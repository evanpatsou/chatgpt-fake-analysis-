{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce538a1",
   "metadata": {},
   "source": [
    "# SI Opportunity Scoring — Train/Validation Comparison (v5)\n",
    "**Order corrected: Cleaning & filtering first (no numeric mapping inside cleaning)**  \n",
    "**Fixed rule → Data-driven rule → ML (Calibrated Logistic Regression)**  \n",
    "**Last updated:** 2026-02-24\n",
    "\n",
    "## Target (proxy) definition\n",
    "We derive **`si_offering`** from `OFFERING_NAME`:\n",
    "- `si_offering_row = 1` if OFFERING_NAME contains token **SI** (case-insensitive)\n",
    "- `si_offering (per ID) = max(si_offering_row)` across rows for that client\n",
    "\n",
    "## Objective\n",
    "Rank **IDs with `si_offering = 0`** by predicted SI alignment from preferences.\n",
    "\n",
    "## Key design choice\n",
    "**Cleaning is only cleaning and filtering** (no numeric mapping).\n",
    "Numeric mappings happen later in **Feature encoding**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6191b3",
   "metadata": {},
   "source": [
    "---\n",
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473ac63",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Load raw data + shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eff36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data.csv\")  # <-- change to your real file path\n",
    "\n",
    "def make_synthetic_data(n=9000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return pd.DataFrame({\n",
    "        \"ID\": rng.integers(1, n//2 + 1, size=n),\n",
    "        \"IO_TYPE\": rng.choice([\"normal\", \"zombie\"], size=n, p=[0.97, 0.03]),\n",
    "        \"LIFE_CYCLE\": rng.choice([\"open\", \"closed\"], size=n, p=[0.9, 0.1]),\n",
    "        \"OFFERING_NAME\": rng.choice(\n",
    "            [\"Core\", \"Standard\", \"ESG Plus\", \"SI Focus\", \"Core SI\", \"Income\", \"SI Sustainable\", None],\n",
    "            size=n, p=[0.23,0.23,0.14,0.14,0.08,0.07,0.06,0.05]\n",
    "        ),\n",
    "        \"SI_CONSIDERATION_CD\": rng.choice([\"S1\",\"S2\",\"S3\", None], size=n, p=[0.35,0.35,0.2,0.1]),\n",
    "        \"SFDR_PREF\": rng.choice([\"F1\",\"F2\",\"F3\", None], size=n, p=[0.4,0.35,0.2,0.05]),\n",
    "        \"SFDR_ACTUAL\": rng.choice([\"F1\",\"F2\",\"F3\", None], size=n, p=[0.45,0.35,0.15,0.05]),\n",
    "        \"PAI_PREF\": rng.choice([\"PAI Selected\", None], size=n, p=[0.3,0.7]),\n",
    "        \"MIFID\": rng.choice([\"Yes\",\"No\", None], size=n, p=[0.55,0.4,0.05]),\n",
    "        \"TAXONOMYPREF\": rng.choice([\"A1\",\"A2\",\"A3\", None], size=n, p=[0.5,0.35,0.1,0.05]),\n",
    "        \"GHG\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.25,0.65,0.05,0.05]),\n",
    "        \"Biodiversity\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.2,0.7,0.05,0.05]),\n",
    "        \"Water\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.22,0.68,0.05,0.05]),\n",
    "        \"Waste\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.18,0.72,0.05,0.05]),\n",
    "        \"Social\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.28,0.62,0.05,0.05]),\n",
    "    })\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    df_raw = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Loaded: {DATA_PATH}  shape={df_raw.shape}\")\n",
    "else:\n",
    "    df_raw = make_synthetic_data()\n",
    "    print(\"DATA_PATH not found; using synthetic demo dataset.\")\n",
    "    print(f\"shape={df_raw.shape}\")\n",
    "\n",
    "df_raw = df_raw.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74748119",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Cleaning & filtering (ONLY)\n",
    "\n",
    "Filters and standardization only. No numeric mappings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_RAW = [\n",
    "    \"ID\",\"IO_TYPE\",\"LIFE_CYCLE\",\"OFFERING_NAME\",\n",
    "    \"SI_CONSIDERATION_CD\",\"SFDR_PREF\",\"SFDR_ACTUAL\",\"PAI_PREF\",\"MIFID\",\"TAXONOMYPREF\",\n",
    "    \"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"\n",
    "]\n",
    "missing_cols = [c for c in REQUIRED_RAW if c not in df_raw.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required raw columns: {missing_cols}\")\n",
    "\n",
    "def clean_filter_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # strip whitespace in object cols\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            df[c] = df[c].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    # standardize placeholder missing\n",
    "    df = df.replace({\"--\": np.nan, \"\": np.nan})\n",
    "\n",
    "    before = len(df)\n",
    "    df = df[df[\"IO_TYPE\"].fillna(\"\").str.lower() != \"zombie\"]\n",
    "    after_zombie = len(df)\n",
    "    df = df[df[\"LIFE_CYCLE\"].fillna(\"\").str.lower() == \"open\"]\n",
    "    after_open = len(df)\n",
    "\n",
    "    df.attrs[\"cleaning_summary\"] = {\n",
    "        \"before\": before,\n",
    "        \"after_remove_zombie\": after_zombie,\n",
    "        \"after_keep_open\": after_open,\n",
    "        \"removed_zombie\": before - after_zombie,\n",
    "        \"removed_closed\": after_zombie - after_open\n",
    "    }\n",
    "    return df\n",
    "\n",
    "df_clean_rows = clean_filter_only(df_raw)\n",
    "pd.DataFrame([df_clean_rows.attrs[\"cleaning_summary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5bedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_clean_rows.attrs[\"cleaning_summary\"]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar([\"Before\", \"After zombie\", \"After open\"], [s[\"before\"], s[\"after_remove_zombie\"], s[\"after_keep_open\"]])\n",
    "plt.title(\"Cleaning impact: rows remaining after filters\")\n",
    "plt.ylabel(\"Rows\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "key_cols = [\"SI_CONSIDERATION_CD\",\"SFDR_PREF\",\"SFDR_ACTUAL\",\"TAXONOMYPREF\",\"MIFID\",\"PAI_PREF\",\n",
    "            \"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\",\"OFFERING_NAME\"]\n",
    "miss = df_clean_rows[key_cols].isna().mean().sort_values(ascending=False)\n",
    "\n",
    "display(miss.to_frame(\"missing_rate\").head(12))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(miss.index[:12], miss.values[:12])\n",
    "plt.title(\"Top missing rates after cleaning (raw values)\")\n",
    "plt.ylabel(\"Missing rate\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f77c17",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) Derive SI label + aggregate to ID-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44143389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean_rows.copy()\n",
    "df[\"si_offering_row\"] = df[\"OFFERING_NAME\"].astype(str).str.contains(r\"\\bSI\\b\", case=False, na=False).astype(int)\n",
    "\n",
    "def mode_or_first(s: pd.Series):\n",
    "    s2 = s.dropna()\n",
    "    if len(s2) == 0:\n",
    "        return np.nan\n",
    "    m = s2.mode()\n",
    "    return m.iloc[0] if len(m) else s2.iloc[0]\n",
    "\n",
    "agg_dict = {\n",
    "    \"IO_TYPE\": mode_or_first,\n",
    "    \"LIFE_CYCLE\": mode_or_first,\n",
    "    \"OFFERING_NAME\": mode_or_first,\n",
    "    \"SI_CONSIDERATION_CD\": mode_or_first,\n",
    "    \"SFDR_PREF\": mode_or_first,\n",
    "    \"SFDR_ACTUAL\": mode_or_first,\n",
    "    \"PAI_PREF\": mode_or_first,\n",
    "    \"MIFID\": mode_or_first,\n",
    "    \"TAXONOMYPREF\": mode_or_first,\n",
    "    \"GHG\": mode_or_first,\n",
    "    \"Biodiversity\": mode_or_first,\n",
    "    \"Water\": mode_or_first,\n",
    "    \"Waste\": mode_or_first,\n",
    "    \"Social\": mode_or_first,\n",
    "    \"si_offering_row\": \"max\",\n",
    "}\n",
    "\n",
    "df_id = df.groupby(\"ID\", as_index=False).agg(agg_dict).rename(columns={\"si_offering_row\":\"si_offering\"})\n",
    "\n",
    "sizes = pd.DataFrame({\n",
    "    \"level\": [\"row-level (cleaned)\", \"ID-level\"],\n",
    "    \"rows\": [len(df), len(df_id)],\n",
    "    \"si_offering_rate\": [df[\"si_offering_row\"].mean(), df_id[\"si_offering\"].mean()]\n",
    "})\n",
    "display(sizes)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(sizes[\"level\"], sizes[\"rows\"])\n",
    "plt.title(\"Size: cleaned rows vs ID-level\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(sizes[\"level\"], sizes[\"si_offering_rate\"])\n",
    "plt.title(\"Proxy label prevalence: si_offering rate\")\n",
    "plt.ylabel(\"Rate\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ae29c",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Feature encoding and engineering (numbers happen here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SI = {\"S1\":1, \"S2\":2, \"S3\":3}\n",
    "MAP_SFDR = {\"F1\":1, \"F2\":2, \"F3\":3}\n",
    "MAP_TAX = {\"A1\":1, \"A2\":2, \"A3\":3}\n",
    "\n",
    "def yes_to_1(x):\n",
    "    return 1 if isinstance(x, str) and x.strip().lower() == \"yes\" else 0\n",
    "\n",
    "def encode_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    for c in [\"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"]:\n",
    "        df[c] = df[c].apply(yes_to_1).astype(int)\n",
    "\n",
    "    df[\"MIFID\"] = df[\"MIFID\"].apply(yes_to_1).astype(int)\n",
    "    df[\"PAI_PREF\"] = (df[\"PAI_PREF\"].astype(str).str.lower() == \"pai selected\").astype(int)\n",
    "\n",
    "    df[\"SI_CONSIDERATION_num\"] = df[\"SI_CONSIDERATION_CD\"].map(MAP_SI).fillna(1).astype(int)\n",
    "    df[\"SFDR_PREF_num\"] = df[\"SFDR_PREF\"].map(MAP_SFDR).fillna(1).astype(int)\n",
    "    df[\"SFDR_ACTUAL_num\"] = df[\"SFDR_ACTUAL\"].map(MAP_SFDR).fillna(1).astype(int)\n",
    "    df[\"TAXONOMYPREF_num\"] = df[\"TAXONOMYPREF\"].map(MAP_TAX).fillna(1).astype(int)\n",
    "\n",
    "    df[\"sfdr_gap\"] = np.clip(df[\"SFDR_PREF_num\"] - df[\"SFDR_ACTUAL_num\"], -2, 2)\n",
    "    df[\"sfdr_opp\"] = np.maximum(df[\"sfdr_gap\"], 0)\n",
    "\n",
    "    topic_cols = [\"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"]\n",
    "    df[\"esg_topics_yes_cnt\"] = df[topic_cols].sum(axis=1)\n",
    "    df[\"esg_topics_yes_share\"] = df[\"esg_topics_yes_cnt\"] / len(topic_cols)\n",
    "\n",
    "    df[\"si_norm\"] = np.clip((df[\"SI_CONSIDERATION_num\"] - 1)/2, 0, 1)\n",
    "    df[\"sfdr_norm\"] = np.clip(df[\"sfdr_opp\"]/2, 0, 1)\n",
    "    df[\"topics_norm\"] = np.clip(df[\"esg_topics_yes_share\"], 0, 1)\n",
    "    df[\"topics_if_pai\"] = df[\"topics_norm\"] * df[\"PAI_PREF\"]\n",
    "    df[\"tax_norm\"] = np.clip((df[\"TAXONOMYPREF_num\"] - 1)/2, 0, 1)\n",
    "\n",
    "    df[\"si_offering\"] = df[\"si_offering\"].astype(int)\n",
    "    return df\n",
    "\n",
    "df_feat = encode_features(df_id)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_feat[\"sfdr_gap\"], bins=5)\n",
    "plt.title(\"Distribution of sfdr_gap\")\n",
    "plt.xlabel(\"sfdr_gap\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_feat[\"TAXONOMYPREF_num\"], bins=3)\n",
    "plt.title(\"Distribution of TAXONOMYPREF_num (A1/A2/A3)\")\n",
    "plt.xlabel(\"TAXONOMYPREF_num\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_feat[[\"ID\",\"si_offering\",\"MIFID\",\"sfdr_gap\",\"PAI_PREF\",\"TAXONOMYPREF_num\",\"esg_topics_yes_cnt\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358091d",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) Fixed-weight rule score (branching) — includes Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RuleConfig:\n",
    "    si_score_s1: float = 20\n",
    "    si_score_s2: float = 50\n",
    "    si_score_s3: float = 80\n",
    "    w_sfdr: float = 0.60\n",
    "    w_pai_block: float = 0.25\n",
    "    w_tax: float = 0.15\n",
    "\n",
    "cfg = RuleConfig()\n",
    "\n",
    "def score_fixed_rule(df: pd.DataFrame, cfg: RuleConfig) -> pd.Series:\n",
    "    si_score = df[\"SI_CONSIDERATION_num\"].map({1: cfg.si_score_s1, 2: cfg.si_score_s2, 3: cfg.si_score_s3}).astype(float)\n",
    "    pai_block = np.where(df[\"PAI_PREF\"] == 1, 0.5 + 0.5*df[\"topics_norm\"], 0.0)\n",
    "    score_B = 100 * (cfg.w_sfdr*df[\"sfdr_norm\"] + cfg.w_pai_block*pai_block + cfg.w_tax*df[\"tax_norm\"])\n",
    "    score = np.where(df[\"MIFID\"]==1, score_B, si_score)\n",
    "    return pd.Series(np.clip(score, 0, 100), index=df.index)\n",
    "\n",
    "df_feat[\"score_fixed\"] = score_fixed_rule(df_feat, cfg)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_feat[\"score_fixed\"], bins=30)\n",
    "plt.title(\"Score distribution: Fixed-weight rule\")\n",
    "plt.xlabel(\"score_fixed\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51c7bb",
   "metadata": {},
   "source": [
    "---\n",
    "## 6) Train/Validation split (ID-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752fa283",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_ALL = [\n",
    "    \"si_norm\",\"sfdr_norm\",\"PAI_PREF\",\"topics_if_pai\",\"tax_norm\",\n",
    "    \"esg_topics_yes_cnt\",\"sfdr_gap\",\"MIFID\",\"SI_CONSIDERATION_num\",\"TAXONOMYPREF_num\"\n",
    "]\n",
    "\n",
    "X = df_feat[FEATURES_ALL].copy()\n",
    "y = df_feat[\"si_offering\"].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "idx_train, idx_val = X_train.index, X_val.index\n",
    "\n",
    "print(\"Train:\", len(idx_train), \"Val:\", len(idx_val))\n",
    "print(\"Train si rate:\", y_train.mean().round(4), \"Val si rate:\", y_val.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d9a86",
   "metadata": {},
   "source": [
    "---\n",
    "## 7) Evaluation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_scores(y_true, p, label):\n",
    "    return {\"model\": label,\n",
    "            \"auc\": roc_auc_score(y_true, p),\n",
    "            \"avg_precision\": average_precision_score(y_true, p),\n",
    "            \"brier\": brier_score_loss(y_true, p)}\n",
    "\n",
    "def lift_table(y_true, p, n_bins=10):\n",
    "    tmp = pd.DataFrame({\"y\": y_true, \"p\": p})\n",
    "    tmp[\"bin\"] = pd.qcut(tmp[\"p\"], n_bins, labels=False, duplicates=\"drop\") + 1\n",
    "    return tmp.groupby(\"bin\")[\"y\"].agg([\"mean\",\"count\"]).rename(columns={\"mean\":\"si_rate\"})\n",
    "\n",
    "def plot_lift(tab, title):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(tab.index, tab[\"si_rate\"].values, marker=\"o\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Decile (1=lowest, 10=highest)\")\n",
    "    plt.ylabel(\"si_offering rate\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908e3f5",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Method 1 — Fixed-weight rule (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e419030",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fixed_val = df_feat.loc[idx_val, \"score_fixed\"].values / 100.0\n",
    "fixed_metrics = eval_scores(y_val.values, p_fixed_val, \"Fixed-weight rule\")\n",
    "display(fixed_metrics)\n",
    "\n",
    "lift_fixed = lift_table(y_val.values, p_fixed_val)\n",
    "plot_lift(lift_fixed, \"Lift (proxy): Fixed-weight rule\")\n",
    "display(lift_fixed)\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_val.values, p_fixed_val, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.title(\"Calibration (proxy): Fixed-weight rule\")\n",
    "plt.xlabel(\"Predicted (score_fixed/100)\")\n",
    "plt.ylabel(\"Observed si rate\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fd609",
   "metadata": {},
   "source": [
    "---\n",
    "## 9) Method 2 — Data-driven rule (learn Branch B weights on train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_B = df_feat.loc[idx_train]\n",
    "train_B = train_B[train_B[\"MIFID\"]==1].copy()\n",
    "\n",
    "DD_B_FEATURES = [\"sfdr_norm\",\"PAI_PREF\",\"topics_if_pai\",\"tax_norm\"]\n",
    "lr_dd_B = LogisticRegression(max_iter=6000, class_weight=\"balanced\")\n",
    "lr_dd_B.fit(train_B[DD_B_FEATURES], train_B[\"si_offering\"])\n",
    "\n",
    "coef_B = pd.Series(lr_dd_B.coef_[0], index=DD_B_FEATURES).sort_values(key=np.abs, ascending=False)\n",
    "display(coef_B.to_frame(\"coef\"))\n",
    "\n",
    "pos = np.maximum(coef_B.values, 0)\n",
    "if pos.sum() == 0:\n",
    "    pos = np.ones_like(pos)\n",
    "w_dd_B = pd.Series(100*pos/pos.sum(), index=coef_B.index).sort_values(ascending=False)\n",
    "display(w_dd_B.to_frame(\"weight_100\"))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(w_dd_B.index, w_dd_B.values)\n",
    "plt.title(\"Learned Branch-B weights (sum=100)\")\n",
    "plt.ylabel(\"weight\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Score\n",
    "df_feat[\"score_datadriven\"] = np.nan\n",
    "si_score = df_feat[\"SI_CONSIDERATION_num\"].map({1: cfg.si_score_s1, 2: cfg.si_score_s2, 3: cfg.si_score_s3}).astype(float)\n",
    "df_feat.loc[df_feat[\"MIFID\"]==0, \"score_datadriven\"] = si_score[df_feat[\"MIFID\"]==0]\n",
    "\n",
    "scoreB = (w_dd_B[\"sfdr_norm\"]*df_feat[\"sfdr_norm\"] +\n",
    "          w_dd_B[\"PAI_PREF\"]*df_feat[\"PAI_PREF\"] +\n",
    "          w_dd_B[\"topics_if_pai\"]*df_feat[\"topics_if_pai\"] +\n",
    "          w_dd_B[\"tax_norm\"]*df_feat[\"tax_norm\"])\n",
    "df_feat.loc[df_feat[\"MIFID\"]==1, \"score_datadriven\"] = scoreB[df_feat[\"MIFID\"]==1]\n",
    "df_feat[\"score_datadriven\"] = df_feat[\"score_datadriven\"].clip(0,100)\n",
    "\n",
    "p_dd_val = df_feat.loc[idx_val, \"score_datadriven\"].values / 100.0\n",
    "dd_metrics = eval_scores(y_val.values, p_dd_val, \"Data-driven rule\")\n",
    "display(dd_metrics)\n",
    "\n",
    "lift_dd = lift_table(y_val.values, p_dd_val)\n",
    "plot_lift(lift_dd, \"Lift (proxy): Data-driven rule\")\n",
    "display(lift_dd)\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_val.values, p_dd_val, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.title(\"Calibration (proxy): Data-driven rule\")\n",
    "plt.xlabel(\"Predicted (score_datadriven/100)\")\n",
    "plt.ylabel(\"Observed si rate\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a59187",
   "metadata": {},
   "source": [
    "---\n",
    "## 10) Method 3 — ML: Calibrated Logistic Regression (train → validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_FEATURES = FEATURES_ALL\n",
    "Xtr = X_train[ML_FEATURES].copy()\n",
    "Xva = X_val[ML_FEATURES].copy()\n",
    "\n",
    "lr = LogisticRegression(max_iter=7000, class_weight=\"balanced\")\n",
    "cal_lr = CalibratedClassifierCV(lr, method=\"isotonic\", cv=5)\n",
    "cal_lr.fit(Xtr, y_train)\n",
    "\n",
    "p_lr_val = cal_lr.predict_proba(Xva)[:,1]\n",
    "ml_metrics = eval_scores(y_val.values, p_lr_val, \"ML: Calibrated Logistic Regression\")\n",
    "display(ml_metrics)\n",
    "\n",
    "lift_lr = lift_table(y_val.values, p_lr_val)\n",
    "plot_lift(lift_lr, \"Lift (proxy): ML Calibrated Logistic Regression\")\n",
    "display(lift_lr)\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_val.values, p_lr_val, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.title(\"Calibration (proxy): ML Calibrated Logistic Regression\")\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"Observed si rate\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5056a0",
   "metadata": {},
   "source": [
    "---\n",
    "## 11) Compare validation performance (3 methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5574584",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame([fixed_metrics, dd_metrics, ml_metrics]).round(4)\n",
    "display(comparison.sort_values(\"auc\", ascending=False))\n",
    "\n",
    "for metric in [\"auc\",\"avg_precision\",\"brier\"]:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(comparison[\"model\"], comparison[metric])\n",
    "    plt.title(f\"Validation comparison: {metric}\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f2315a",
   "metadata": {},
   "source": [
    "---\n",
    "## 12) Operational output: rank `si_offering=0` IDs + buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK_METHOD = \"score_datadriven\"  # score_fixed or score_datadriven\n",
    "\n",
    "df_out = df_feat.copy()\n",
    "df_out[\"rank_score\"] = df_out[RANK_METHOD]\n",
    "df_out[\"score_percentile\"] = (df_out[\"rank_score\"].rank(pct=True) * 100).round(2)\n",
    "df_out[\"bucket_3\"] = pd.cut(df_out[\"score_percentile\"], bins=[-0.01, 50, 80, 100], labels=[\"Low\",\"Average\",\"High\"])\n",
    "\n",
    "targets = df_out[df_out[\"si_offering\"]==0].sort_values(\"rank_score\", ascending=False)\n",
    "targets[[\"ID\",\"rank_score\",\"score_percentile\",\"bucket_3\",\"MIFID\",\"sfdr_gap\",\"PAI_PREF\",\"TAXONOMYPREF_num\",\"esg_topics_yes_cnt\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c1bd7",
   "metadata": {},
   "source": [
    "---\n",
    "## 13) Pilot plan\n",
    "\n",
    "Use High bucket for treatment, random control, measure response/adoption, retrain on true outcomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
