{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68679713",
   "metadata": {},
   "source": [
    "# SI Opportunity Scoring — Recommended Modeling Notebook (v9)\n",
    "**Champion model:** Weighted rule scorecard (data-driven, constrained, explainable)  \n",
    "**Challenger model:** Calibrated Logistic Regression (shadow mode until pilot labels)  \n",
    "**Evaluation:** lift/precision at top buckets + calibration + governance\n",
    "\n",
    "**Last updated:** 2026-02-27\n",
    "\n",
    "---\n",
    "\n",
    "## Business problem\n",
    "We want to find **client IDs with `si_offering = 0`** (not currently in an SI offering) that are **most likely to be interested** in an SI offering.\n",
    "\n",
    "## What makes this tricky\n",
    "We do *not* have a perfect “interest” label. Our initial benchmark label is a **proxy**:\n",
    "- `si_offering = 1` if the client appears in an offering whose name contains the token **SI** (from `OFFERING_NAME`)\n",
    "\n",
    "This label is useful for comparing methods, but it can be biased by commercial processes.  \n",
    "Therefore, the optimal strategy is to:\n",
    "1) start with a **constrained scorecard** (robust to label noise, easy governance)  \n",
    "2) run a **pilot** to collect true outcomes (responses / adoption / pipeline)  \n",
    "3) then upgrade to ML / uplift modeling using real labels.\n",
    "\n",
    "---\n",
    "\n",
    "## Modeling logic (recommended)\n",
    "### Branching by MiFID\n",
    "- If `MIFID = 0` -> score uses **only** `SI_CONSIDERATION`\n",
    "- If `MIFID = 1` -> score = **alpha * SI + (1-alpha) * Confirmations**\n",
    "  - SI is the anchor (trusted explicit signal)\n",
    "  - Confirmations come from: **SFDR opportunity**, **PAI + topics**, **Taxonomy (A1/A2/A3)**\n",
    "\n",
    "### Why alpha (SI vs confirmations)?\n",
    "- If alpha too high -> ignore useful confirmation evidence\n",
    "- If alpha too low -> over-infer preferences -> irrelevant outreach risk\n",
    "\n",
    "We start with **alpha=0.80** (stakeholder-friendly) and learn an improved alpha from data **within bounds** (e.g., 0.60–0.90).\n",
    "\n",
    "---\n",
    "\n",
    "## Methods compared (same train/validation split)\n",
    "1) **Fixed rule**: alpha fixed (0.80), confirmation weights fixed  \n",
    "2) **Weighted rule (champion)**: learn confirmation weights + learn alpha (bounded)  \n",
    "3) **ML (challenger)**: Calibrated Logistic Regression with MiFID interactions\n",
    "\n",
    "Success is primarily about **top-bucket ROI**, so we emphasize:\n",
    "- **Lift / Precision@K** (top 10%, 20%)\n",
    "- **Decile lift curves**\n",
    "- **Calibration** (probability reliability for bucket thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1de939",
   "metadata": {},
   "source": [
    "---\n",
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a788506",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Load raw data + shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data.csv\")  # <-- change to your real file path\n",
    "\n",
    "def make_synthetic_data(n=9000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return pd.DataFrame({\n",
    "        \"ID\": rng.integers(1, n//2 + 1, size=n),\n",
    "        \"IO_TYPE\": rng.choice([\"normal\", \"zombie\"], size=n, p=[0.97, 0.03]),\n",
    "        \"LIFE_CYCLE\": rng.choice([\"open\", \"closed\"], size=n, p=[0.9, 0.1]),\n",
    "        \"OFFERING_NAME\": rng.choice(\n",
    "            [\"Core\", \"Standard\", \"ESG Plus\", \"SI Focus\", \"Core SI\", \"Income\", \"SI Sustainable\", None],\n",
    "            size=n, p=[0.23,0.23,0.14,0.14,0.08,0.07,0.06,0.05]\n",
    "        ),\n",
    "        \"SI_CONSIDERATION_CD\": rng.choice([\"S1\",\"S2\",\"S3\", None], size=n, p=[0.35,0.35,0.2,0.1]),\n",
    "        \"SFDR_PREF\": rng.choice([\"F1\",\"F2\",\"F3\", None], size=n, p=[0.4,0.35,0.2,0.05]),\n",
    "        \"SFDR_ACTUAL\": rng.choice([\"F1\",\"F2\",\"F3\", None], size=n, p=[0.45,0.35,0.15,0.05]),\n",
    "        \"PAI_PREF\": rng.choice([\"PAI Selected\", None], size=n, p=[0.3,0.7]),\n",
    "        \"MIFID\": rng.choice([\"Yes\",\"No\", None], size=n, p=[0.55,0.4,0.05]),\n",
    "        \"TAXONOMYPREF\": rng.choice([\"A1\",\"A2\",\"A3\", None], size=n, p=[0.5,0.35,0.1,0.05]),\n",
    "        \"GHG\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.25,0.65,0.05,0.05]),\n",
    "        \"Biodiversity\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.2,0.7,0.05,0.05]),\n",
    "        \"Water\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.22,0.68,0.05,0.05]),\n",
    "        \"Waste\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.18,0.72,0.05,0.05]),\n",
    "        \"Social\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.28,0.62,0.05,0.05]),\n",
    "    })\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    df_raw = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Loaded: {DATA_PATH}  shape={df_raw.shape}\")\n",
    "else:\n",
    "    df_raw = make_synthetic_data()\n",
    "    print(\"DATA_PATH not found; using synthetic demo dataset.\")\n",
    "    print(f\"shape={df_raw.shape}\")\n",
    "\n",
    "# Shuffle to avoid ordering artifacts\n",
    "df_raw = df_raw.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6585f",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Cleaning & filtering (ONLY)\n",
    "\n",
    "This step is **only** hygiene: filtering + missing normalization. No category->number mappings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fee179",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_RAW = [\n",
    "    \"ID\",\"IO_TYPE\",\"LIFE_CYCLE\",\"OFFERING_NAME\",\n",
    "    \"SI_CONSIDERATION_CD\",\"SFDR_PREF\",\"SFDR_ACTUAL\",\"PAI_PREF\",\"MIFID\",\"TAXONOMYPREF\",\n",
    "    \"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"\n",
    "]\n",
    "missing_cols = [c for c in REQUIRED_RAW if c not in df_raw.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required raw columns: {missing_cols}\")\n",
    "\n",
    "def clean_filter_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # Trim strings\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            df[c] = df[c].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    # Normalize placeholder missing\n",
    "    df = df.replace({\"--\": np.nan, \"\": np.nan})\n",
    "\n",
    "    before = len(df)\n",
    "    df = df[df[\"IO_TYPE\"].fillna(\"\").str.lower() != \"zombie\"]\n",
    "    after_zombie = len(df)\n",
    "    df = df[df[\"LIFE_CYCLE\"].fillna(\"\").str.lower() == \"open\"]\n",
    "    after_open = len(df)\n",
    "\n",
    "    df.attrs[\"cleaning_summary\"] = {\n",
    "        \"before\": before,\n",
    "        \"after_remove_zombie\": after_zombie,\n",
    "        \"after_keep_open\": after_open,\n",
    "        \"removed_zombie\": before - after_zombie,\n",
    "        \"removed_closed\": after_zombie - after_open\n",
    "    }\n",
    "    return df\n",
    "\n",
    "df_clean = clean_filter_only(df_raw)\n",
    "pd.DataFrame([df_clean.attrs[\"cleaning_summary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning impact chart\n",
    "s = df_clean.attrs[\"cleaning_summary\"]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar([\"Before\", \"After zombie\", \"After open\"], [s[\"before\"], s[\"after_remove_zombie\"], s[\"after_keep_open\"]])\n",
    "plt.title(\"Cleaning impact: rows remaining after filters\")\n",
    "plt.ylabel(\"Rows\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Missingness snapshot (raw values)\n",
    "key_cols = [\"SI_CONSIDERATION_CD\",\"SFDR_PREF\",\"SFDR_ACTUAL\",\"TAXONOMYPREF\",\"MIFID\",\"PAI_PREF\",\n",
    "            \"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\",\"OFFERING_NAME\"]\n",
    "miss = df_clean[key_cols].isna().mean().sort_values(ascending=False)\n",
    "display(miss.to_frame(\"missing_rate\").head(12))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(miss.index[:12], miss.values[:12])\n",
    "plt.title(\"Top missing rates after cleaning (raw values)\")\n",
    "plt.ylabel(\"Missing rate\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a8043",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) Target derivation + ID-level aggregation\n",
    "\n",
    "We recommend **clients (IDs)**, so we aggregate to one row per ID.\n",
    "\n",
    "**Proxy label:** `si_offering = 1` if any row for the client has `OFFERING_NAME` containing token `SI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d192165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "df[\"si_offering_row\"] = df[\"OFFERING_NAME\"].astype(str).str.contains(r\"\\bSI\\b\", case=False, na=False).astype(int)\n",
    "\n",
    "def mode_or_first(s: pd.Series):\n",
    "    s2 = s.dropna()\n",
    "    if len(s2) == 0:\n",
    "        return np.nan\n",
    "    m = s2.mode()\n",
    "    return m.iloc[0] if len(m) else s2.iloc[0]\n",
    "\n",
    "agg = {\n",
    "    \"OFFERING_NAME\": mode_or_first,\n",
    "    \"SI_CONSIDERATION_CD\": mode_or_first,\n",
    "    \"SFDR_PREF\": mode_or_first,\n",
    "    \"SFDR_ACTUAL\": mode_or_first,\n",
    "    \"PAI_PREF\": mode_or_first,\n",
    "    \"MIFID\": mode_or_first,\n",
    "    \"TAXONOMYPREF\": mode_or_first,\n",
    "    \"GHG\": mode_or_first,\n",
    "    \"Biodiversity\": mode_or_first,\n",
    "    \"Water\": mode_or_first,\n",
    "    \"Waste\": mode_or_first,\n",
    "    \"Social\": mode_or_first,\n",
    "    \"si_offering_row\": \"max\",\n",
    "}\n",
    "df_id = df.groupby(\"ID\", as_index=False).agg(agg).rename(columns={\"si_offering_row\":\"si_offering\"})\n",
    "df_id[\"si_offering\"] = df_id[\"si_offering\"].astype(int)\n",
    "\n",
    "sizes = pd.DataFrame({\n",
    "    \"level\": [\"row-level (cleaned)\", \"ID-level\"],\n",
    "    \"rows\": [len(df), len(df_id)],\n",
    "    \"si_offering_rate\": [df[\"si_offering_row\"].mean(), df_id[\"si_offering\"].mean()]\n",
    "})\n",
    "display(sizes)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(sizes[\"level\"], sizes[\"rows\"])\n",
    "plt.title(\"Size: cleaned rows vs ID-level\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(sizes[\"level\"], sizes[\"si_offering_rate\"])\n",
    "plt.title(\"Proxy label prevalence: si_offering rate\")\n",
    "plt.ylabel(\"Rate\")\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b77f67",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Feature mappings\n",
    "\n",
    "Stakeholder-friendly mapping table for key engineered features (kept intentionally small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = pd.DataFrame([\n",
    "    [\"SI_CONSIDERATION_CD\", \"S1/S2/S3\", \"si_norm\", \"S1=0, S2=0.5, S3=1\"],\n",
    "    [\"MIFID\", \"Yes/No\", \"MIFID\", \"Yes=1, No/NA=0\"],\n",
    "    [\"SFDR_PREF / SFDR_ACTUAL\", \"F1/F2/F3\", \"sfdr_gap, sfdr_norm\", \"sfdr_gap=clip(pref-actual,-2,2); sfdr_norm=max(gap,0)/2\"],\n",
    "    [\"PAI_PREF + topics\", \"PAI Selected + ESG topics\", \"pai_block\", \"0 if no PAI else 0.5 + 0.5*topics_norm\"],\n",
    "    [\"TAXONOMYPREF\", \"A1/A2/A3\", \"tax_norm\", \"A1=0, A2=0.5, A3=1 (scaled)\"],\n",
    "], columns=[\"Raw field(s)\", \"Raw values\", \"Engineered feature\", \"Definition\"])\n",
    "display(feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d8c57",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) Encoding + engineered signals\n",
    "\n",
    "Numeric encoding happens here.\n",
    "\n",
    "### SFDR opportunity\n",
    "- `sfdr_gap = clip(pref - actual, -2, 2)`\n",
    "- `sfdr_norm = max(sfdr_gap, 0) / 2` (range 0..1)\n",
    "\n",
    "This ensures only **pref > actual** drives opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43aa0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SI = {\"S1\":1, \"S2\":2, \"S3\":3}\n",
    "MAP_SFDR = {\"F1\":1, \"F2\":2, \"F3\":3}\n",
    "MAP_TAX = {\"A1\":1, \"A2\":2, \"A3\":3}\n",
    "\n",
    "def yes_to_1(x):\n",
    "    return 1 if isinstance(x, str) and x.strip().lower() == \"yes\" else 0\n",
    "\n",
    "def encode(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # Topics Yes/No -> 1/0\n",
    "    for c in [\"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"]:\n",
    "        df[c] = df[c].apply(yes_to_1).astype(int)\n",
    "\n",
    "    # MIFID Yes/No -> 1/0\n",
    "    df[\"MIFID\"] = df[\"MIFID\"].apply(yes_to_1).astype(int)\n",
    "\n",
    "    # PAI flag\n",
    "    df[\"PAI_PREF\"] = (df[\"PAI_PREF\"].astype(str).str.lower() == \"pai selected\").astype(int)\n",
    "\n",
    "    # Ordinals (default to lowest tier when missing)\n",
    "    df[\"SI_CONSIDERATION_num\"] = df[\"SI_CONSIDERATION_CD\"].map(MAP_SI).fillna(1).astype(int)\n",
    "    df[\"SFDR_PREF_num\"] = df[\"SFDR_PREF\"].map(MAP_SFDR).fillna(1).astype(int)\n",
    "    df[\"SFDR_ACTUAL_num\"] = df[\"SFDR_ACTUAL\"].map(MAP_SFDR).fillna(1).astype(int)\n",
    "    df[\"TAXONOMYPREF_num\"] = df[\"TAXONOMYPREF\"].map(MAP_TAX).fillna(1).astype(int)\n",
    "\n",
    "    # Engineered\n",
    "    df[\"sfdr_gap\"] = np.clip(df[\"SFDR_PREF_num\"] - df[\"SFDR_ACTUAL_num\"], -2, 2)\n",
    "    df[\"sfdr_norm\"] = np.maximum(df[\"sfdr_gap\"], 0) / 2.0   # 0..1 only (opportunity side)\n",
    "\n",
    "    topic_cols = [\"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"]\n",
    "    df[\"esg_topics_yes_cnt\"] = df[topic_cols].sum(axis=1)\n",
    "    df[\"topics_norm\"] = df[\"esg_topics_yes_cnt\"] / len(topic_cols)\n",
    "\n",
    "    df[\"pai_block\"] = np.where(df[\"PAI_PREF\"]==1, 0.5 + 0.5*df[\"topics_norm\"], 0.0)  # 0..1\n",
    "\n",
    "    df[\"si_norm\"] = np.clip((df[\"SI_CONSIDERATION_num\"] - 1)/2, 0, 1)  # S1=0, S2=0.5, S3=1\n",
    "    df[\"tax_norm\"] = np.clip((df[\"TAXONOMYPREF_num\"] - 1)/2, 0, 1)      # A1=0, A2=0.5, A3=1\n",
    "\n",
    "    return df\n",
    "\n",
    "df_feat = encode(df_id)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_feat[\"sfdr_gap\"], bins=5)\n",
    "plt.title(\"sfdr_gap distribution (clipped [-2,2])\")\n",
    "plt.xlabel(\"sfdr_gap\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_feat[\"sfdr_norm\"], bins=10)\n",
    "plt.title(\"sfdr_norm distribution (opportunity only, 0..1)\")\n",
    "plt.xlabel(\"sfdr_norm\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_feat[[\"ID\",\"si_offering\",\"MIFID\",\"SI_CONSIDERATION_num\",\"si_norm\",\"sfdr_gap\",\"sfdr_norm\",\"PAI_PREF\",\"pai_block\",\"TAXONOMYPREF_num\",\"tax_norm\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283a13b",
   "metadata": {},
   "source": [
    "---\n",
    "## 6) Worked example (about 60%)\n",
    "\n",
    "A stakeholder-friendly example under the **fixed rule**:\n",
    "- MIFID = 1\n",
    "- SI = S2 -> si_norm = 0.5\n",
    "- Strong confirmations -> confirm = 1.0\n",
    "- alpha = 0.80\n",
    "\n",
    "Score = 100 * (0.8*0.5 + 0.2*1.0) = 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.DataFrame([{\n",
    "    \"MIFID\": 1,\n",
    "    \"si_norm\": 0.5,\n",
    "    \"sfdr_norm\": 1.0,\n",
    "    \"pai_block\": 1.0,\n",
    "    \"tax_norm\": 1.0\n",
    "}])\n",
    "\n",
    "alpha = 0.80\n",
    "w = {\"sfdr_norm\":0.50, \"pai_block\":0.30, \"tax_norm\":0.20}\n",
    "confirm = w[\"sfdr_norm\"]*example[\"sfdr_norm\"] + w[\"pai_block\"]*example[\"pai_block\"] + w[\"tax_norm\"]*example[\"tax_norm\"]\n",
    "score = 100*(alpha*example[\"si_norm\"] + (1-alpha)*confirm)\n",
    "\n",
    "display(example.assign(confirm=confirm.round(3), score_percent=score.round(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d179b",
   "metadata": {},
   "source": [
    "---\n",
    "## 7) Train/Validation split\n",
    "\n",
    "We evaluate all methods on the **same held-out validation** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6304a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_feat[\"si_offering\"].astype(int).copy()\n",
    "BASE_COLS = [\"MIFID\",\"si_norm\",\"sfdr_norm\",\"pai_block\",\"tax_norm\"]\n",
    "X = df_feat[BASE_COLS].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "idx_train, idx_val = X_train.index, X_val.index\n",
    "\n",
    "print(\"Train:\", len(idx_train), \"Val:\", len(idx_val))\n",
    "print(\"Train si rate:\", y_train.mean().round(4), \"Val si rate:\", y_val.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586f569",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Evaluation helpers (stakeholder metrics)\n",
    "\n",
    "Primary operational metrics focus on the top bucket:\n",
    "- Precision@K (top 10%, top 20%)\n",
    "- Lift@K (top K positive rate / baseline rate)\n",
    "- Decile lift curve\n",
    "- Calibration curve\n",
    "\n",
    "We also report AUC/AP/Brier for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d50e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_global(y_true, p, label):\n",
    "    return {\n",
    "        \"model\": label,\n",
    "        \"auc\": roc_auc_score(y_true, p),\n",
    "        \"avg_precision\": average_precision_score(y_true, p),\n",
    "        \"brier\": brier_score_loss(y_true, p)\n",
    "    }\n",
    "\n",
    "def precision_lift_at_frac(y_true, p, frac=0.10):\n",
    "    n = len(p)\n",
    "    k = max(1, int(np.ceil(frac*n)))\n",
    "    order = np.argsort(-p)\n",
    "    top = y_true[order][:k]\n",
    "    baseline = y_true.mean()\n",
    "    prec = top.mean() if k > 0 else np.nan\n",
    "    lift = (prec / baseline) if baseline > 0 else np.nan\n",
    "    return {\"frac\": frac, \"k\": k, \"precision\": prec, \"lift\": lift, \"baseline\": baseline}\n",
    "\n",
    "def lift_by_decile(y_true, p, n_bins=10):\n",
    "    tmp = pd.DataFrame({\"y\": y_true, \"p\": p})\n",
    "    tmp[\"decile\"] = pd.qcut(tmp[\"p\"], n_bins, labels=False, duplicates=\"drop\") + 1\n",
    "    out = tmp.groupby(\"decile\")[\"y\"].agg([\"mean\",\"count\"]).rename(columns={\"mean\":\"si_rate\"})\n",
    "    return out\n",
    "\n",
    "def plot_lift_curve(tab, title):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(tab.index, tab[\"si_rate\"].values, marker=\"o\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Decile (1=lowest, 10=highest)\")\n",
    "    plt.ylabel(\"si_offering rate\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_calibration(y_true, p, title):\n",
    "    prob_true, prob_pred = calibration_curve(y_true, p, n_bins=10, strategy=\"quantile\")\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Observed rate\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638e587f",
   "metadata": {},
   "source": [
    "---\n",
    "## 9) Method 1 — Fixed rule (baseline)\n",
    "\n",
    "Fixed, stakeholder-friendly parameters:\n",
    "- alpha = 0.80\n",
    "- confirmation weights: SFDR 50%, PAI 30%, Taxonomy 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35615d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FixedCfg:\n",
    "    alpha: float = 0.80\n",
    "    w_sfdr: float = 0.50\n",
    "    w_pai: float = 0.30\n",
    "    w_tax: float = 0.20\n",
    "\n",
    "cfg_fixed = FixedCfg()\n",
    "\n",
    "def score_fixed(df: pd.DataFrame, cfg: FixedCfg) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    confirm = cfg.w_sfdr*df[\"sfdr_norm\"] + cfg.w_pai*df[\"pai_block\"] + cfg.w_tax*df[\"tax_norm\"]\n",
    "    score_m1 = cfg.alpha*df[\"si_norm\"] + (1-cfg.alpha)*confirm\n",
    "    score_m0 = df[\"si_norm\"]\n",
    "    p = np.where(df[\"MIFID\"]==1, score_m1, score_m0)\n",
    "    df[\"p_fixed\"] = np.clip(p, 0, 1)\n",
    "\n",
    "    # Explainability\n",
    "    df[\"why_si\"] = np.where(df[\"MIFID\"]==1, cfg.alpha*df[\"si_norm\"], df[\"si_norm\"])\n",
    "    df[\"why_sfdr\"] = np.where(df[\"MIFID\"]==1, (1-cfg.alpha)*cfg.w_sfdr*df[\"sfdr_norm\"], 0.0)\n",
    "    df[\"why_pai\"]  = np.where(df[\"MIFID\"]==1, (1-cfg.alpha)*cfg.w_pai*df[\"pai_block\"], 0.0)\n",
    "    df[\"why_tax\"]  = np.where(df[\"MIFID\"]==1, (1-cfg.alpha)*cfg.w_tax*df[\"tax_norm\"], 0.0)\n",
    "    return df\n",
    "\n",
    "df_scored = score_fixed(df_feat, cfg_fixed)\n",
    "\n",
    "p_fixed_val = df_scored.loc[idx_val, \"p_fixed\"].values\n",
    "fixed_global = eval_global(y_val.values, p_fixed_val, \"Fixed rule (alpha=0.80)\")\n",
    "fixed_top10 = precision_lift_at_frac(y_val.values, p_fixed_val, 0.10)\n",
    "fixed_top20 = precision_lift_at_frac(y_val.values, p_fixed_val, 0.20)\n",
    "\n",
    "display(pd.DataFrame([fixed_global]))\n",
    "display(pd.DataFrame([fixed_top10, fixed_top20]))\n",
    "\n",
    "tab = lift_by_decile(y_val.values, p_fixed_val)\n",
    "display(tab)\n",
    "plot_lift_curve(tab, \"Lift by decile: Fixed rule\")\n",
    "plot_calibration(y_val.values, p_fixed_val, \"Calibration: Fixed rule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65cb19",
   "metadata": {},
   "source": [
    "---\n",
    "## 10) Method 2 — Weighted rule (recommended champion)\n",
    "\n",
    "Same formula as fixed rule, but we learn:\n",
    "1) confirmation weights (SFDR/PAI/Tax)\n",
    "2) alpha split (bounded, conservative)\n",
    "\n",
    "This keeps the score **rule-like**, explainable, and data-driven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn confirmation weights on train subset where MIFID=1\n",
    "train_df = df_scored.loc[idx_train].copy()\n",
    "train_m1 = train_df[train_df[\"MIFID\"]==1].copy()\n",
    "\n",
    "CONF = [\"sfdr_norm\",\"pai_block\",\"tax_norm\"]\n",
    "\n",
    "if train_m1[\"si_offering\"].nunique() < 2:\n",
    "    print(\"Warning: MIFID=1 train subset has one class; fallback to fixed weights.\")\n",
    "    w_learn = pd.Series([cfg_fixed.w_sfdr, cfg_fixed.w_pai, cfg_fixed.w_tax], index=CONF)\n",
    "else:\n",
    "    lr_w = LogisticRegression(max_iter=6000, class_weight=\"balanced\")\n",
    "    lr_w.fit(train_m1[CONF], train_m1[\"si_offering\"])\n",
    "    coef = pd.Series(lr_w.coef_[0], index=CONF)\n",
    "\n",
    "    # Stakeholder-friendly monotonic constraint: keep non-negative contributions\n",
    "    pos = np.maximum(coef.values, 0)\n",
    "    if pos.sum() == 0:\n",
    "        pos = np.ones_like(pos)\n",
    "    w_learn = pd.Series(pos/pos.sum(), index=CONF)\n",
    "\n",
    "display(w_learn.to_frame(\"learned_weight\"))\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(w_learn.index, w_learn.values)\n",
    "plt.title(\"Learned confirmation weights (sum=1)\")\n",
    "plt.ylabel(\"weight\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Choose alpha by CV on train (optimize Average Precision; bounded)\n",
    "alpha_grid = np.round(np.arange(0.60, 0.91, 0.05), 2)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def score_prob(df: pd.DataFrame, alpha: float, w: pd.Series) -> np.ndarray:\n",
    "    confirm = w[\"sfdr_norm\"]*df[\"sfdr_norm\"] + w[\"pai_block\"]*df[\"pai_block\"] + w[\"tax_norm\"]*df[\"tax_norm\"]\n",
    "    m1 = alpha*df[\"si_norm\"].values + (1-alpha)*confirm.values\n",
    "    m0 = df[\"si_norm\"].values\n",
    "    return np.clip(np.where(df[\"MIFID\"].values==1, m1, m0), 0, 1)\n",
    "\n",
    "rows=[]\n",
    "train_idx = idx_train.values\n",
    "for a in alpha_grid:\n",
    "    aps=[]\n",
    "    for tr_i, te_i in skf.split(train_idx, y_train.values):\n",
    "        te_ix = train_idx[te_i]\n",
    "        df_te = df_scored.loc[te_ix]\n",
    "        p = score_prob(df_te, a, w_learn)\n",
    "        aps.append(average_precision_score(df_te[\"si_offering\"].values, p))\n",
    "    rows.append({\"alpha\": a, \"cv_ap_mean\": float(np.mean(aps))})\n",
    "\n",
    "alpha_perf = pd.DataFrame(rows).sort_values(\"cv_ap_mean\", ascending=False)\n",
    "display(alpha_perf)\n",
    "\n",
    "alpha_best = float(alpha_perf.iloc[0][\"alpha\"])\n",
    "print(\"Selected alpha (max CV AP):\", alpha_best)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "tmp = alpha_perf.sort_values(\"alpha\")\n",
    "plt.plot(tmp[\"alpha\"], tmp[\"cv_ap_mean\"], marker=\"o\")\n",
    "plt.title(\"Selecting alpha by CV Average Precision (train)\")\n",
    "plt.xlabel(\"alpha (weight on SI)\")\n",
    "plt.ylabel(\"CV AP\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Apply weighted score\n",
    "df_scored[\"p_weighted\"] = score_prob(df_scored, alpha_best, w_learn)\n",
    "\n",
    "# Explainability (why columns)\n",
    "df_scored[\"whyW_si\"] = np.where(df_scored[\"MIFID\"]==1, alpha_best*df_scored[\"si_norm\"], df_scored[\"si_norm\"])\n",
    "df_scored[\"whyW_sfdr\"] = np.where(df_scored[\"MIFID\"]==1, (1-alpha_best)*w_learn[\"sfdr_norm\"]*df_scored[\"sfdr_norm\"], 0.0)\n",
    "df_scored[\"whyW_pai\"]  = np.where(df_scored[\"MIFID\"]==1, (1-alpha_best)*w_learn[\"pai_block\"]*df_scored[\"pai_block\"], 0.0)\n",
    "df_scored[\"whyW_tax\"]  = np.where(df_scored[\"MIFID\"]==1, (1-alpha_best)*w_learn[\"tax_norm\"]*df_scored[\"tax_norm\"], 0.0)\n",
    "\n",
    "p_w_val = df_scored.loc[idx_val, \"p_weighted\"].values\n",
    "w_global = eval_global(y_val.values, p_w_val, f\"Weighted rule (alpha={alpha_best})\")\n",
    "w_top10 = precision_lift_at_frac(y_val.values, p_w_val, 0.10)\n",
    "w_top20 = precision_lift_at_frac(y_val.values, p_w_val, 0.20)\n",
    "\n",
    "display(pd.DataFrame([w_global]))\n",
    "display(pd.DataFrame([w_top10, w_top20]))\n",
    "\n",
    "tab = lift_by_decile(y_val.values, p_w_val)\n",
    "display(tab)\n",
    "plot_lift_curve(tab, \"Lift by decile: Weighted rule (champion)\")\n",
    "plot_calibration(y_val.values, p_w_val, \"Calibration: Weighted rule (champion)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f876a44",
   "metadata": {},
   "source": [
    "---\n",
    "## 11) Method 3 — ML (Calibrated Logistic Regression) — challenger\n",
    "\n",
    "ML is run in shadow mode until we have pilot labels.\n",
    "\n",
    "To respect the business structure, we use MiFID interaction features, so confirmations only matter when `MIFID=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = pd.DataFrame(index=df.index)\n",
    "    X[\"si_norm\"] = df[\"si_norm\"]\n",
    "    X[\"MIFID\"] = df[\"MIFID\"]\n",
    "    X[\"m1_sfdr\"] = df[\"MIFID\"] * df[\"sfdr_norm\"]\n",
    "    X[\"m1_pai\"]  = df[\"MIFID\"] * df[\"pai_block\"]\n",
    "    X[\"m1_tax\"]  = df[\"MIFID\"] * df[\"tax_norm\"]\n",
    "    return X\n",
    "\n",
    "Xtr = ml_matrix(df_scored.loc[idx_train])\n",
    "Xva = ml_matrix(df_scored.loc[idx_val])\n",
    "\n",
    "base_lr = LogisticRegression(max_iter=8000, class_weight=\"balanced\")\n",
    "cal_lr = CalibratedClassifierCV(base_lr, method=\"isotonic\", cv=5)\n",
    "cal_lr.fit(Xtr, y_train)\n",
    "\n",
    "p_ml_val = cal_lr.predict_proba(Xva)[:,1]\n",
    "ml_global = eval_global(y_val.values, p_ml_val, \"ML: Calibrated LR\")\n",
    "ml_top10 = precision_lift_at_frac(y_val.values, p_ml_val, 0.10)\n",
    "ml_top20 = precision_lift_at_frac(y_val.values, p_ml_val, 0.20)\n",
    "\n",
    "display(pd.DataFrame([ml_global]))\n",
    "display(pd.DataFrame([ml_top10, ml_top20]))\n",
    "\n",
    "tab = lift_by_decile(y_val.values, p_ml_val)\n",
    "display(tab)\n",
    "plot_lift_curve(tab, \"Lift by decile: ML (calibrated LR)\")\n",
    "plot_calibration(y_val.values, p_ml_val, \"Calibration: ML (calibrated LR)\")\n",
    "\n",
    "# Interpretability: coefficients from an uncalibrated LR fitted on same features\n",
    "plain_lr = LogisticRegression(max_iter=8000, class_weight=\"balanced\")\n",
    "plain_lr.fit(Xtr, y_train)\n",
    "coef = pd.Series(plain_lr.coef_[0], index=Xtr.columns).sort_values(key=np.abs, ascending=False)\n",
    "display(coef.to_frame(\"coef\"))\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.bar(coef.index[:10], coef.values[:10])\n",
    "plt.title(\"Top coefficients (uncalibrated LR; sign indicates direction)\")\n",
    "plt.ylabel(\"coef\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c281ac",
   "metadata": {},
   "source": [
    "---\n",
    "## 12) Compare all methods on validation\n",
    "\n",
    "We choose the champion based on top-bucket lift/precision and stability.\n",
    "\n",
    "Recommendation: use the Weighted rule as the default unless ML is materially better and stable over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame([fixed_global, w_global, ml_global]).round(4)\n",
    "display(comparison)\n",
    "\n",
    "topk = pd.DataFrame([\n",
    "    {\"model\": \"Fixed\", **fixed_top10},\n",
    "    {\"model\": \"Fixed\", **fixed_top20},\n",
    "    {\"model\": \"Weighted\", **w_top10},\n",
    "    {\"model\": \"Weighted\", **w_top20},\n",
    "    {\"model\": \"ML\", **ml_top10},\n",
    "    {\"model\": \"ML\", **ml_top20},\n",
    "]).round(4)\n",
    "display(topk)\n",
    "\n",
    "for metric in [\"auc\",\"avg_precision\",\"brier\"]:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(comparison[\"model\"], comparison[metric])\n",
    "    plt.title(f\"Validation comparison: {metric}\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=20, ha=\"right\")\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf02005b",
   "metadata": {},
   "source": [
    "---\n",
    "## 13) Operational output\n",
    "\n",
    "Output format:\n",
    "- rank clients with `si_offering=0`\n",
    "- add percentiles + buckets (Low/Average/High)\n",
    "- include why columns so the list is explainable\n",
    "\n",
    "Default: use the Weighted rule probability `p_weighted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_scored.copy()\n",
    "df_out[\"rank_prob\"] = df_out[\"p_weighted\"]\n",
    "df_out[\"score_percentile\"] = (df_out[\"rank_prob\"].rank(pct=True) * 100).round(2)\n",
    "df_out[\"bucket_3\"] = pd.cut(df_out[\"score_percentile\"], bins=[-0.01, 50, 80, 100], labels=[\"Low\",\"Average\",\"High\"])\n",
    "\n",
    "targets = df_out[df_out[\"si_offering\"]==0].sort_values(\"rank_prob\", ascending=False).head(20)\n",
    "\n",
    "cols = [\n",
    "    \"ID\",\"rank_prob\",\"score_percentile\",\"bucket_3\",\n",
    "    \"MIFID\",\"SI_CONSIDERATION_num\",\"sfdr_gap\",\"PAI_PREF\",\"TAXONOMYPREF_num\",\"esg_topics_yes_cnt\",\n",
    "    \"whyW_si\",\"whyW_sfdr\",\"whyW_pai\",\"whyW_tax\"\n",
    "]\n",
    "targets[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707fdd1",
   "metadata": {},
   "source": [
    "---\n",
    "## 14) Risks & governance\n",
    "\n",
    "### Key risks\n",
    "- Label bias: proxy membership is not true interest\n",
    "- Leakage risk: never use `OFFERING_NAME` as a feature (we only use it to build the proxy label)\n",
    "- Drift: questionnaire completion, product naming, and advisory behavior change over time\n",
    "- Missing data: defaulting to lowest tier can under-score clients\n",
    "\n",
    "### Controls\n",
    "- Monitor monthly: missingness, score distributions, top-bucket hit rate\n",
    "- Refit: confirmation weights + alpha quarterly (or after process change)\n",
    "- Keep a human review step for the highest-ranked edge cases\n",
    "- Use ML only if it stays calibrated and stable\n",
    "\n",
    "### Why not kNN/SVM here\n",
    "- Harder explainability and operational calibration\n",
    "- More sensitivity to scaling and missingness\n",
    "- Higher overfit risk with proxy labels\n",
    "Calibrated LR is usually the best trade-off for stakeholder trust + performance in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226fa94",
   "metadata": {},
   "source": [
    "---\n",
    "## 15) Pilot plan (to create true labels)\n",
    "\n",
    "To make this truly optimal, we need true outcomes.\n",
    "\n",
    "### Pilot design\n",
    "- Population: `si_offering=0`\n",
    "- Treatment: top bucket (e.g., top 20% by weighted rule)\n",
    "- Control: randomized sample from remaining eligible IDs\n",
    "- Outcomes: response, meeting booked, adoption / mandate change, pipeline created\n",
    "\n",
    "### Next modeling step (post-pilot)\n",
    "Train on true outcomes and consider uplift modeling (incremental impact of outreach), which is the real ROI-optimal objective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
