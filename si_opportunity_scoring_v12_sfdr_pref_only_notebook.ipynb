{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7017b2c",
   "metadata": {},
   "source": [
    "# SI Opportunity Scoring — SFDR Pref Only (v12)\n",
    "**Change requested:** remove SFDR opportunity and use **SFDR_PREF** (not SFDR_ACTUAL) as the SFDR confirmation signal.  \n",
    "**Goal:** rank **IDs with `si_offering = 0`** by likelihood of SI interest.\n",
    "\n",
    "**Business logic**\n",
    "- If `MIFID = 0` → score uses **only** `SI_CONSIDERATION`\n",
    "- If `MIFID = 1` → score = **α · SI + (1−α) · Confirmations**\n",
    "  - Confirmations = **SFDR_PREF + PAI + Taxonomy**\n",
    "  - Start with **α=0.80** as a stakeholder-friendly baseline\n",
    "  - Learn a better α (bounded) for the data-driven weighted rule\n",
    "\n",
    "**Methods compared on the same validation split**\n",
    "1) Fixed rule (transparent baseline)  \n",
    "2) Weighted rule (learn confirmation weights + learn α within bounds)  \n",
    "3) ML (Calibrated Logistic Regression; challenger)\n",
    "\n",
    "**Last updated:** 2026-02-27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63200c",
   "metadata": {},
   "source": [
    "---\n",
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19bec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2116d7",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Load raw data + shuffle rows\n",
    "\n",
    "We shuffle to avoid ordering artifacts in operational extracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data.csv\")  # <-- change to your real file path\n",
    "\n",
    "def make_synthetic_data(n=9000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return pd.DataFrame({\n",
    "        \"ID\": rng.integers(1, n//2 + 1, size=n),\n",
    "        \"IO_TYPE\": rng.choice([\"normal\", \"zombie\"], size=n, p=[0.97, 0.03]),\n",
    "        \"LIFE_CYCLE\": rng.choice([\"open\", \"closed\"], size=n, p=[0.9, 0.1]),\n",
    "        \"OFFERING_NAME\": rng.choice(\n",
    "            [\"Core\", \"Standard\", \"ESG Plus\", \"SI Focus\", \"Core SI\", \"Income\", \"SI Sustainable\", None],\n",
    "            size=n, p=[0.23,0.23,0.14,0.14,0.08,0.07,0.06,0.05]\n",
    "        ),\n",
    "        \"SI_CONSIDERATION_CD\": rng.choice([\"S1\",\"S2\",\"S3\", None], size=n, p=[0.35,0.35,0.2,0.1]),\n",
    "        \"SFDR_PREF\": rng.choice([\"F1\",\"F2\",\"F3\", None], size=n, p=[0.4,0.35,0.2,0.05]),\n",
    "        \"SFDR_ACTUAL\": rng.choice([\"F1\",\"F2\",\"F3\", None], size=n, p=[0.45,0.35,0.15,0.05]),  # kept as raw, not used in scoring\n",
    "        \"PAI_PREF\": rng.choice([\"PAI Selected\", \"Yes\", \"No\", None], size=n, p=[0.25,0.1,0.05,0.6]),\n",
    "        \"MIFID\": rng.choice([\"Yes\",\"No\", None], size=n, p=[0.55,0.4,0.05]),\n",
    "        \"TAXONOMYPREF\": rng.choice([\"A1\",\"A2\",\"A3\", None], size=n, p=[0.5,0.35,0.1,0.05]),\n",
    "        \"GHG\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.25,0.65,0.05,0.05]),\n",
    "        \"Biodiversity\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.2,0.7,0.05,0.05]),\n",
    "        \"Water\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.22,0.68,0.05,0.05]),\n",
    "        \"Waste\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.18,0.72,0.05,0.05]),\n",
    "        \"Social\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.28,0.62,0.05,0.05]),\n",
    "    })\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    df_raw = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Loaded: {DATA_PATH}  shape={df_raw.shape}\")\n",
    "else:\n",
    "    df_raw = make_synthetic_data()\n",
    "    print(\"DATA_PATH not found; using synthetic demo dataset.\")\n",
    "    print(f\"shape={df_raw.shape}\")\n",
    "\n",
    "df_raw = df_raw.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae5776",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Cleaning & filtering (ONLY)\n",
    "\n",
    "Hygiene step only: filtering + missing normalization. No category-to-number mapping here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_RAW = [\n",
    "    \"ID\",\"IO_TYPE\",\"LIFE_CYCLE\",\"OFFERING_NAME\",\n",
    "    \"SI_CONSIDERATION_CD\",\"SFDR_PREF\",\"PAI_PREF\",\"MIFID\",\"TAXONOMYPREF\",\n",
    "    \"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"\n",
    "]\n",
    "missing_cols = [c for c in REQUIRED_RAW if c not in df_raw.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required raw columns: {missing_cols}\")\n",
    "\n",
    "def clean_filter_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            df[c] = df[c].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    df = df.replace({\"--\": np.nan, \"\": np.nan})\n",
    "\n",
    "    before = len(df)\n",
    "    df = df[df[\"IO_TYPE\"].fillna(\"\").str.lower() != \"zombie\"]\n",
    "    after_zombie = len(df)\n",
    "    df = df[df[\"LIFE_CYCLE\"].fillna(\"\").str.lower() == \"open\"]\n",
    "    after_open = len(df)\n",
    "\n",
    "    df.attrs[\"cleaning_summary\"] = {\n",
    "        \"before\": before,\n",
    "        \"after_remove_zombie\": after_zombie,\n",
    "        \"after_keep_open\": after_open,\n",
    "        \"removed_zombie\": before - after_zombie,\n",
    "        \"removed_closed\": after_zombie - after_open\n",
    "    }\n",
    "    return df\n",
    "\n",
    "df_clean = clean_filter_only(df_raw)\n",
    "pd.DataFrame([df_clean.attrs[\"cleaning_summary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d719ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_clean.attrs[\"cleaning_summary\"]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar([\"Before\",\"After zombie\",\"After open\"], [s[\"before\"], s[\"after_remove_zombie\"], s[\"after_keep_open\"]])\n",
    "plt.title(\"Cleaning impact: rows remaining after filters\")\n",
    "plt.ylabel(\"Rows\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "key_cols = [\"SI_CONSIDERATION_CD\",\"SFDR_PREF\",\"PAI_PREF\",\"MIFID\",\"TAXONOMYPREF\",\n",
    "            \"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\",\"OFFERING_NAME\"]\n",
    "miss = df_clean[key_cols].isna().mean().sort_values(ascending=False)\n",
    "display(miss.to_frame(\"missing_rate\").head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e363d",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) Derive proxy label + aggregate to ID-level\n",
    "\n",
    "We recommend **clients (IDs)**, so we aggregate to one row per ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3675dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "df[\"si_offering_row\"] = df[\"OFFERING_NAME\"].astype(str).str.contains(r\"\\bSI\\b\", case=False, na=False).astype(int)\n",
    "\n",
    "def mode_or_first(s: pd.Series):\n",
    "    s2 = s.dropna()\n",
    "    if len(s2) == 0:\n",
    "        return np.nan\n",
    "    m = s2.mode()\n",
    "    return m.iloc[0] if len(m) else s2.iloc[0]\n",
    "\n",
    "agg = {\n",
    "    \"OFFERING_NAME\": mode_or_first,\n",
    "    \"SI_CONSIDERATION_CD\": mode_or_first,\n",
    "    \"SFDR_PREF\": mode_or_first,\n",
    "    \"PAI_PREF\": mode_or_first,\n",
    "    \"MIFID\": mode_or_first,\n",
    "    \"TAXONOMYPREF\": mode_or_first,\n",
    "    \"GHG\": mode_or_first,\n",
    "    \"Biodiversity\": mode_or_first,\n",
    "    \"Water\": mode_or_first,\n",
    "    \"Waste\": mode_or_first,\n",
    "    \"Social\": mode_or_first,\n",
    "    \"si_offering_row\": \"max\",\n",
    "}\n",
    "df_id = df.groupby(\"ID\", as_index=False).agg(agg).rename(columns={\"si_offering_row\":\"si_offering\"})\n",
    "df_id[\"si_offering\"] = df_id[\"si_offering\"].astype(int)\n",
    "\n",
    "sizes = pd.DataFrame({\n",
    "    \"level\":[\"row-level (cleaned)\",\"ID-level\"],\n",
    "    \"rows\":[len(df), len(df_id)],\n",
    "    \"si_offering_rate\":[df[\"si_offering_row\"].mean(), df_id[\"si_offering\"].mean()]\n",
    "})\n",
    "display(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2139c",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Feature mappings (simple stakeholder table)\n",
    "\n",
    "**SFDR change:** we use `SFDR_PREF` only (no SFDR opportunity; no SFDR_ACTUAL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135fa6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = pd.DataFrame([\n",
    "    [\"SI_CONSIDERATION_CD\", \"S1/S2/S3\", \"si_norm\", \"S1=0, S2=0.5, S3=1\"],\n",
    "    [\"MIFID\", \"Yes/No\", \"MIFID\", \"Yes=1 else 0\"],\n",
    "    [\"SFDR_PREF\", \"F1/F2/F3\", \"sfdr_pref_norm\", \"F1=0, F2=0.5, F3=1\"],\n",
    "    [\"PAI_PREF + topics\", \"PAI selected + ESG topics\", \"pai_block\", \"0 if no PAI else 0.5 + 0.5*topics_norm\"],\n",
    "    [\"TAXONOMYPREF\", \"A1/A2/A3\", \"tax_norm\", \"A1=0, A2=0.5, A3=1\"],\n",
    "], columns=[\"Raw field(s)\",\"Raw values\",\"Engineered feature\",\"Definition\"])\n",
    "display(feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8124c",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) Encoding & engineered signals\n",
    "\n",
    "We encode values into small, interpretable 0..1 signals.\n",
    "\n",
    "**Note:** we keep missing flags for diagnostics and for ML, but the rule score uses the primary signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SI = {\"S1\":1, \"S2\":2, \"S3\":3}\n",
    "MAP_SFDR = {\"F1\":1, \"F2\":2, \"F3\":3}\n",
    "MAP_TAX = {\"A1\":1, \"A2\":2, \"A3\":3}\n",
    "\n",
    "def parse_yes_no(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, np.integer)):\n",
    "        return 1 if x == 1 else 0\n",
    "    if isinstance(x, (float, np.floating)):\n",
    "        return 1 if x > 0.5 else 0\n",
    "    if isinstance(x, str):\n",
    "        t = x.strip().lower()\n",
    "        if t in {\"yes\",\"y\",\"true\",\"1\",\"selected\"}:\n",
    "            return 1\n",
    "        if t in {\"no\",\"n\",\"false\",\"0\"}:\n",
    "            return 0\n",
    "    return np.nan\n",
    "\n",
    "def parse_pai_selected(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return 0\n",
    "    if isinstance(x, (int, np.integer)):\n",
    "        return 1 if x == 1 else 0\n",
    "    if isinstance(x, str):\n",
    "        t = x.strip().lower()\n",
    "        # robust: catches \"PAI Selected\", \"pai: yes\", \"selected\", etc.\n",
    "        if \"pai\" in t and (\"select\" in t or \"yes\" in t or \"true\" in t or t.endswith(\"1\")):\n",
    "            return 1\n",
    "        if t in {\"pai selected\",\"selected\",\"yes\",\"true\",\"1\"}:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def parse_sfdr_pref(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return np.nan\n",
    "    if isinstance(x, str):\n",
    "        t = x.strip().upper()\n",
    "        for k in [\"F1\",\"F2\",\"F3\"]:\n",
    "            if k in t:\n",
    "                return MAP_SFDR[k]\n",
    "    return np.nan\n",
    "\n",
    "def encode(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Topics\n",
    "    for c in [\"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"]:\n",
    "        yn = df[c].apply(parse_yes_no)\n",
    "        df[c] = yn.fillna(0).astype(int)\n",
    "\n",
    "    # MiFID\n",
    "    df[\"MIFID\"] = df[\"MIFID\"].apply(parse_yes_no).fillna(0).astype(int)\n",
    "\n",
    "    # SI\n",
    "    df[\"SI_CONSIDERATION_num\"] = df[\"SI_CONSIDERATION_CD\"].map(MAP_SI)\n",
    "    df[\"si_missing\"] = df[\"SI_CONSIDERATION_num\"].isna().astype(int)\n",
    "    df[\"SI_CONSIDERATION_num\"] = df[\"SI_CONSIDERATION_num\"].fillna(1).astype(int)\n",
    "    df[\"si_norm\"] = np.clip((df[\"SI_CONSIDERATION_num\"] - 1)/2, 0, 1)\n",
    "\n",
    "    # SFDR pref\n",
    "    df[\"SFDR_PREF_num\"] = df[\"SFDR_PREF\"].apply(parse_sfdr_pref)\n",
    "    df[\"sfdr_pref_missing\"] = df[\"SFDR_PREF_num\"].isna().astype(int)\n",
    "    pref_filled = df[\"SFDR_PREF_num\"].fillna(1)\n",
    "    df[\"sfdr_pref_norm\"] = np.clip((pref_filled - 1)/2, 0, 1)  # F1=0, F2=0.5, F3=1\n",
    "\n",
    "    # Taxonomy\n",
    "    df[\"TAXONOMYPREF_num\"] = df[\"TAXONOMYPREF\"].map(MAP_TAX)\n",
    "    df[\"tax_missing\"] = df[\"TAXONOMYPREF_num\"].isna().astype(int)\n",
    "    df[\"TAXONOMYPREF_num\"] = df[\"TAXONOMYPREF_num\"].fillna(1).astype(int)\n",
    "    df[\"tax_norm\"] = np.clip((df[\"TAXONOMYPREF_num\"] - 1)/2, 0, 1)\n",
    "\n",
    "    # PAI block\n",
    "    df[\"pai_selected\"] = df[\"PAI_PREF\"].apply(parse_pai_selected).astype(int)\n",
    "    topic_cols = [\"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"]\n",
    "    df[\"esg_topics_yes_cnt\"] = df[topic_cols].sum(axis=1)\n",
    "    df[\"topics_norm\"] = df[\"esg_topics_yes_cnt\"] / len(topic_cols)\n",
    "    df[\"pai_block\"] = np.where(df[\"pai_selected\"]==1, 0.5 + 0.5*df[\"topics_norm\"], 0.0)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_feat = encode(df_id)\n",
    "\n",
    "diag = pd.DataFrame({\n",
    "    \"feature\": [\"si_norm\",\"sfdr_pref_norm\",\"pai_block\",\"tax_norm\",\"sfdr_pref_missing\",\"tax_missing\"],\n",
    "    \"mean\": [df_feat[c].mean() for c in [\"si_norm\",\"sfdr_pref_norm\",\"pai_block\",\"tax_norm\",\"sfdr_pref_missing\",\"tax_missing\"]],\n",
    "    \"nonzero_rate\": [(df_feat[c]!=0).mean() for c in [\"si_norm\",\"sfdr_pref_norm\",\"pai_block\",\"tax_norm\",\"sfdr_pref_missing\",\"tax_missing\"]],\n",
    "}).round(4)\n",
    "display(diag)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_feat[\"sfdr_pref_norm\"], bins=10)\n",
    "plt.title(\"sfdr_pref_norm distribution (F1=0, F2=0.5, F3=1)\")\n",
    "plt.xlabel(\"sfdr_pref_norm\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ed92e",
   "metadata": {},
   "source": [
    "---\n",
    "## 6) Train/validation split\n",
    "We evaluate all three approaches on the same held-out validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_feat[\"si_offering\"].astype(int).copy()\n",
    "\n",
    "BASE_RULE = [\"MIFID\",\"si_norm\",\"sfdr_pref_norm\",\"pai_block\",\"tax_norm\"]\n",
    "X = df_feat[BASE_RULE].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "idx_train, idx_val = X_train.index, X_val.index\n",
    "\n",
    "print(\"Train:\", len(idx_train), \"Val:\", len(idx_val))\n",
    "print(\"Train si rate:\", y_train.mean().round(4), \"Val si rate:\", y_val.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d306f9d",
   "metadata": {},
   "source": [
    "---\n",
    "## 7) Evaluation helpers (stakeholder metrics)\n",
    "\n",
    "We prioritize top-bucket performance (precision/lift at top 10% and 20%), plus lift-by-decile and calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff81a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_global(y_true, p, label):\n",
    "    return {\n",
    "        \"model\": label,\n",
    "        \"auc\": roc_auc_score(y_true, p),\n",
    "        \"avg_precision\": average_precision_score(y_true, p),\n",
    "        \"brier\": brier_score_loss(y_true, p)\n",
    "    }\n",
    "\n",
    "def precision_lift_at_frac(y_true, p, frac=0.10):\n",
    "    n = len(p)\n",
    "    k = max(1, int(np.ceil(frac*n)))\n",
    "    order = np.argsort(-p)\n",
    "    top = y_true[order][:k]\n",
    "    baseline = y_true.mean()\n",
    "    prec = float(top.mean())\n",
    "    lift = float(prec / baseline) if baseline > 0 else np.nan\n",
    "    return {\"frac\": frac, \"k\": k, \"precision\": prec, \"lift\": lift, \"baseline\": float(baseline)}\n",
    "\n",
    "def lift_by_decile(y_true, p, n_bins=10):\n",
    "    tmp = pd.DataFrame({\"y\": y_true, \"p\": p})\n",
    "    tmp[\"decile\"] = pd.qcut(tmp[\"p\"], n_bins, labels=False, duplicates=\"drop\") + 1\n",
    "    out = tmp.groupby(\"decile\")[\"y\"].agg([\"mean\",\"count\"]).rename(columns={\"mean\":\"si_rate\"})\n",
    "    return out\n",
    "\n",
    "def plot_lift_curve(tab, title):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(tab.index, tab[\"si_rate\"].values, marker=\"o\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Decile (1=lowest, 10=highest)\")\n",
    "    plt.ylabel(\"si_offering rate\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_calibration(y_true, p, title):\n",
    "    prob_true, prob_pred = calibration_curve(y_true, p, n_bins=10, strategy=\"quantile\")\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Observed rate\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2062bf",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Method 1 — Fixed rule (baseline)\n",
    "Parameters (stakeholder-friendly default):\n",
    "- alpha = 0.80 (SI anchor)\n",
    "- confirmation weights: SFDR_PREF 50%, PAI 30%, Taxonomy 20%\n",
    "\n",
    "**Scoring**\n",
    "- If MIFID=0 → p = si_norm\n",
    "- If MIFID=1 → p = alpha*si_norm + (1-alpha)*confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FixedCfg:\n",
    "    alpha: float = 0.80\n",
    "    w_sfdr: float = 0.50\n",
    "    w_pai: float = 0.30\n",
    "    w_tax: float = 0.20\n",
    "\n",
    "cfg = FixedCfg()\n",
    "\n",
    "def score_fixed(df: pd.DataFrame, cfg: FixedCfg) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    confirm = cfg.w_sfdr*df[\"sfdr_pref_norm\"] + cfg.w_pai*df[\"pai_block\"] + cfg.w_tax*df[\"tax_norm\"]\n",
    "    m1 = cfg.alpha*df[\"si_norm\"] + (1-cfg.alpha)*confirm\n",
    "    m0 = df[\"si_norm\"]\n",
    "    df[\"p_fixed\"] = np.clip(np.where(df[\"MIFID\"]==1, m1, m0), 0, 1)\n",
    "\n",
    "    # Explainability contributions\n",
    "    df[\"why_si\"] = np.where(df[\"MIFID\"]==1, cfg.alpha*df[\"si_norm\"], df[\"si_norm\"])\n",
    "    df[\"why_sfdr_pref\"] = np.where(df[\"MIFID\"]==1, (1-cfg.alpha)*cfg.w_sfdr*df[\"sfdr_pref_norm\"], 0.0)\n",
    "    df[\"why_pai\"] = np.where(df[\"MIFID\"]==1, (1-cfg.alpha)*cfg.w_pai*df[\"pai_block\"], 0.0)\n",
    "    df[\"why_tax\"] = np.where(df[\"MIFID\"]==1, (1-cfg.alpha)*cfg.w_tax*df[\"tax_norm\"], 0.0)\n",
    "    return df\n",
    "\n",
    "df_scored = score_fixed(df_feat, cfg)\n",
    "\n",
    "p_fixed = df_scored.loc[idx_val, \"p_fixed\"].values\n",
    "fixed_global = eval_global(y_val.values, p_fixed, \"Fixed rule (SFDR_PREF only)\")\n",
    "fixed_top10 = precision_lift_at_frac(y_val.values, p_fixed, 0.10)\n",
    "fixed_top20 = precision_lift_at_frac(y_val.values, p_fixed, 0.20)\n",
    "\n",
    "display(pd.DataFrame([fixed_global]))\n",
    "display(pd.DataFrame([fixed_top10, fixed_top20]))\n",
    "\n",
    "tab = lift_by_decile(y_val.values, p_fixed)\n",
    "display(tab)\n",
    "plot_lift_curve(tab, \"Lift by decile: Fixed rule (SFDR_PREF only)\")\n",
    "plot_calibration(y_val.values, p_fixed, \"Calibration: Fixed rule (SFDR_PREF only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8181ad",
   "metadata": {},
   "source": [
    "---\n",
    "## 9) Method 2 — Weighted rule (data-driven scorecard; recommended champion)\n",
    "We keep the same scorecard structure, but learn from training data:\n",
    "1) confirmation weights (SFDR_PREF / PAI / Taxonomy)\n",
    "2) alpha split within conservative bounds (0.60–0.90)\n",
    "\n",
    "**Governance constraints**\n",
    "- Non-negative confirmation weights (supportive evidence)\n",
    "- Weights normalized to sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f714a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_scored.loc[idx_train].copy()\n",
    "train_m1 = train_df[train_df[\"MIFID\"]==1].copy()\n",
    "\n",
    "CONF = [\"sfdr_pref_norm\",\"pai_block\",\"tax_norm\"]\n",
    "\n",
    "if train_m1[\"si_offering\"].nunique() < 2:\n",
    "    print(\"Warning: MIFID=1 train subset has one class; fallback to fixed weights.\")\n",
    "    w = pd.Series([cfg.w_sfdr, cfg.w_pai, cfg.w_tax], index=CONF)\n",
    "else:\n",
    "    lr_w = LogisticRegression(max_iter=8000, class_weight=\"balanced\")\n",
    "    lr_w.fit(train_m1[CONF], train_m1[\"si_offering\"])\n",
    "    raw_coef = pd.Series(lr_w.coef_[0], index=CONF)\n",
    "    display(raw_coef.to_frame(\"raw_coef (train, MIFID=1)\"))\n",
    "\n",
    "    pos = np.maximum(raw_coef.values, 0)\n",
    "    if pos.sum() == 0:\n",
    "        pos = np.ones_like(pos)\n",
    "    w = pd.Series(pos/pos.sum(), index=CONF)\n",
    "\n",
    "display(w.to_frame(\"learned_weight (sum=1)\"))\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(w.index, w.values)\n",
    "plt.title(\"Learned confirmation weights (sum=1)\")\n",
    "plt.ylabel(\"weight\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def score_prob(df: pd.DataFrame, alpha: float, w: pd.Series) -> np.ndarray:\n",
    "    confirm = w[\"sfdr_pref_norm\"]*df[\"sfdr_pref_norm\"] + w[\"pai_block\"]*df[\"pai_block\"] + w[\"tax_norm\"]*df[\"tax_norm\"]\n",
    "    m1 = alpha*df[\"si_norm\"].values + (1-alpha)*confirm.values\n",
    "    m0 = df[\"si_norm\"].values\n",
    "    return np.clip(np.where(df[\"MIFID\"].values==1, m1, m0), 0, 1)\n",
    "\n",
    "# Choose alpha by CV Average Precision on training data\n",
    "alpha_grid = np.round(np.arange(0.60, 0.91, 0.05), 2)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_idx = idx_train.values\n",
    "rows=[]\n",
    "for a in alpha_grid:\n",
    "    aps=[]\n",
    "    for tr_i, te_i in skf.split(train_idx, y_train.values):\n",
    "        te_ix = train_idx[te_i]\n",
    "        df_te = df_scored.loc[te_ix]\n",
    "        p = score_prob(df_te, a, w)\n",
    "        aps.append(average_precision_score(df_te[\"si_offering\"].values, p))\n",
    "    rows.append({\"alpha\": a, \"cv_ap_mean\": float(np.mean(aps))})\n",
    "\n",
    "alpha_perf = pd.DataFrame(rows).sort_values(\"cv_ap_mean\", ascending=False)\n",
    "display(alpha_perf)\n",
    "\n",
    "alpha_best = float(alpha_perf.iloc[0][\"alpha\"])\n",
    "print(\"Selected alpha:\", alpha_best)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "tmp = alpha_perf.sort_values(\"alpha\")\n",
    "plt.plot(tmp[\"alpha\"], tmp[\"cv_ap_mean\"], marker=\"o\")\n",
    "plt.title(\"Selecting alpha by CV Average Precision (train)\")\n",
    "plt.xlabel(\"alpha (weight on SI)\")\n",
    "plt.ylabel(\"CV AP\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_scored[\"p_weighted\"] = score_prob(df_scored, alpha_best, w)\n",
    "\n",
    "# Why columns for weighted rule\n",
    "df_scored[\"whyW_si\"] = np.where(df_scored[\"MIFID\"]==1, alpha_best*df_scored[\"si_norm\"], df_scored[\"si_norm\"])\n",
    "df_scored[\"whyW_sfdr_pref\"] = np.where(df_scored[\"MIFID\"]==1, (1-alpha_best)*w[\"sfdr_pref_norm\"]*df_scored[\"sfdr_pref_norm\"], 0.0)\n",
    "df_scored[\"whyW_pai\"] = np.where(df_scored[\"MIFID\"]==1, (1-alpha_best)*w[\"pai_block\"]*df_scored[\"pai_block\"], 0.0)\n",
    "df_scored[\"whyW_tax\"] = np.where(df_scored[\"MIFID\"]==1, (1-alpha_best)*w[\"tax_norm\"]*df_scored[\"tax_norm\"], 0.0)\n",
    "\n",
    "p_w = df_scored.loc[idx_val, \"p_weighted\"].values\n",
    "w_global = eval_global(y_val.values, p_w, f\"Weighted rule (alpha={alpha_best})\")\n",
    "w_top10 = precision_lift_at_frac(y_val.values, p_w, 0.10)\n",
    "w_top20 = precision_lift_at_frac(y_val.values, p_w, 0.20)\n",
    "\n",
    "display(pd.DataFrame([w_global]))\n",
    "display(pd.DataFrame([w_top10, w_top20]))\n",
    "\n",
    "tab = lift_by_decile(y_val.values, p_w)\n",
    "display(tab)\n",
    "plot_lift_curve(tab, \"Lift by decile: Weighted rule (SFDR_PREF only)\")\n",
    "plot_calibration(y_val.values, p_w, \"Calibration: Weighted rule (SFDR_PREF only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e322f",
   "metadata": {},
   "source": [
    "---\n",
    "## 10) Method 3 — ML challenger: Calibrated Logistic Regression\n",
    "We keep ML controlled and explainable:\n",
    "- Logistic Regression for interpretability\n",
    "- Isotonic calibration for usable probabilities\n",
    "- MiFID interactions: confirmations contribute primarily when `MIFID=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = pd.DataFrame(index=df.index)\n",
    "    X[\"si_norm\"] = df[\"si_norm\"]\n",
    "    X[\"MIFID\"] = df[\"MIFID\"]\n",
    "    # interactions (only matter when MIFID=1)\n",
    "    X[\"m1_sfdr_pref\"] = df[\"MIFID\"] * df[\"sfdr_pref_norm\"]\n",
    "    X[\"m1_pai\"] = df[\"MIFID\"] * df[\"pai_block\"]\n",
    "    X[\"m1_tax\"] = df[\"MIFID\"] * df[\"tax_norm\"]\n",
    "    # optional missing flags (often help with real data)\n",
    "    X[\"sfdr_pref_missing\"] = df[\"sfdr_pref_missing\"]\n",
    "    X[\"tax_missing\"] = df[\"tax_missing\"]\n",
    "    X[\"si_missing\"] = df[\"si_missing\"]\n",
    "    return X\n",
    "\n",
    "Xtr = ml_matrix(df_scored.loc[idx_train])\n",
    "Xva = ml_matrix(df_scored.loc[idx_val])\n",
    "\n",
    "base_lr = LogisticRegression(max_iter=12000, class_weight=\"balanced\")\n",
    "cal = CalibratedClassifierCV(base_lr, method=\"isotonic\", cv=5)\n",
    "cal.fit(Xtr, y_train)\n",
    "\n",
    "p_ml = cal.predict_proba(Xva)[:,1]\n",
    "ml_global = eval_global(y_val.values, p_ml, \"ML: Calibrated LR (SFDR_PREF only)\")\n",
    "ml_top10 = precision_lift_at_frac(y_val.values, p_ml, 0.10)\n",
    "ml_top20 = precision_lift_at_frac(y_val.values, p_ml, 0.20)\n",
    "\n",
    "display(pd.DataFrame([ml_global]))\n",
    "display(pd.DataFrame([ml_top10, ml_top20]))\n",
    "\n",
    "tab = lift_by_decile(y_val.values, p_ml)\n",
    "display(tab)\n",
    "plot_lift_curve(tab, \"Lift by decile: ML (SFDR_PREF only)\")\n",
    "plot_calibration(y_val.values, p_ml, \"Calibration: ML (SFDR_PREF only)\")\n",
    "\n",
    "# Coefficient sanity-check (uncalibrated LR)\n",
    "plain = LogisticRegression(max_iter=12000, class_weight=\"balanced\")\n",
    "plain.fit(Xtr, y_train)\n",
    "coef = pd.Series(plain.coef_[0], index=Xtr.columns).sort_values(key=np.abs, ascending=False)\n",
    "display(coef.to_frame(\"coef\"))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(coef.index[:12], coef.values[:12])\n",
    "plt.title(\"Top coefficients (uncalibrated LR; direction sanity-check)\")\n",
    "plt.ylabel(\"coef\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c0476",
   "metadata": {},
   "source": [
    "---\n",
    "## 11) Compare validation performance (Fixed vs Weighted vs ML)\n",
    "\n",
    "We select a champion based on top-bucket lift/precision and calibration stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cedd28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame([fixed_global, w_global, ml_global]).round(4)\n",
    "display(comparison)\n",
    "\n",
    "topk = pd.DataFrame([\n",
    "    {\"model\":\"Fixed\", **fixed_top10},\n",
    "    {\"model\":\"Fixed\", **fixed_top20},\n",
    "    {\"model\":\"Weighted\", **w_top10},\n",
    "    {\"model\":\"Weighted\", **w_top20},\n",
    "    {\"model\":\"ML\", **ml_top10},\n",
    "    {\"model\":\"ML\", **ml_top20},\n",
    "]).round(4)\n",
    "display(topk)\n",
    "\n",
    "for metric in [\"auc\",\"avg_precision\",\"brier\"]:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(comparison[\"model\"], comparison[metric])\n",
    "    plt.title(f\"Validation comparison: {metric}\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=20, ha=\"right\")\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f9f3f",
   "metadata": {},
   "source": [
    "---\n",
    "## 12) Operational output: Top 20 IDs with `si_offering=0` + buckets + why columns\n",
    "\n",
    "Default ranking uses the **weighted rule**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76daa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_scored.copy()\n",
    "df_out[\"rank_prob\"] = df_out[\"p_weighted\"]\n",
    "df_out[\"score_percentile\"] = (df_out[\"rank_prob\"].rank(pct=True) * 100).round(2)\n",
    "df_out[\"bucket_3\"] = pd.cut(df_out[\"score_percentile\"], bins=[-0.01,50,80,100], labels=[\"Low\",\"Average\",\"High\"])\n",
    "\n",
    "targets = df_out[df_out[\"si_offering\"]==0].sort_values(\"rank_prob\", ascending=False).head(20)\n",
    "\n",
    "cols = [\n",
    "    \"ID\",\"rank_prob\",\"score_percentile\",\"bucket_3\",\n",
    "    \"MIFID\",\"SI_CONSIDERATION_num\",\"SFDR_PREF_num\",\"pai_selected\",\"TAXONOMYPREF_num\",\"esg_topics_yes_cnt\",\n",
    "    \"whyW_si\",\"whyW_sfdr_pref\",\"whyW_pai\",\"whyW_tax\"\n",
    "]\n",
    "targets[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288fbe0",
   "metadata": {},
   "source": [
    "---\n",
    "## 13) Risks & governance (what to tell stakeholders)\n",
    "- **Proxy label bias:** `si_offering` (membership) is not true intent.\n",
    "- **Leakage control:** do not use OFFERING_NAME as a feature (we only use it for the proxy label).\n",
    "- **Missing data:** can under-score clients; monitor missingness + missing flags.\n",
    "- **Drift:** questionnaire/process/product naming changes → monitor score distributions and lift monthly.\n",
    "\n",
    "**Pilot plan:** run outreach A/B (top bucket vs control) to collect true outcomes and improve labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
