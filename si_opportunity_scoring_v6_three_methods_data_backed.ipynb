{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "296cc54f",
   "metadata": {},
   "source": [
    "# SI Opportunity Scoring — Stakeholder Notebook (v6)\n",
    "**Three methods, one validation: Fixed rule → Weighted (data-driven) rule → ML (Calibrated Logistic Regression)**  \n",
    "**Order:** Cleaning/filtering → Label/ID aggregation → Encoding/Features → Train/Validation → Evaluate 3 methods → Operational output  \n",
    "**Last updated:** 2026-02-27\n",
    "\n",
    "## Goal\n",
    "Identify **IDs with `si_offering = 0`** (not currently in an SI offering) that are **most likely to be interested in SI**.\n",
    "\n",
    "## Proxy target (for benchmarking only)\n",
    "We **derive** `si_offering` from `OFFERING_NAME`:\n",
    "- `si_offering_row = 1` if OFFERING_NAME contains token **SI** (case-insensitive)\n",
    "- `si_offering` (per ID) = max across that ID\n",
    "\n",
    "> This is a *proxy* label: membership ≠ true interest.  \n",
    "> The pilot section explains how to create true labels (response/adoption) and retrain.\n",
    "\n",
    "## Business logic (requested)\n",
    "- **If `MIFID = 0`:** score is based **only** on `SI_CONSIDERATION`  \n",
    "  - S1: **no** interest  \n",
    "  - S2: **some** interest  \n",
    "  - S3: **high** interest  \n",
    "- **If `MIFID = 1`:** we only use **SFDR / PAI / Taxonomy** signals when **`SI_CONSIDERATION` is high (S3)**  \n",
    "  - If SI is not high, keep a low/medium baseline and do not “invent” preferences.\n",
    "\n",
    "This logic is implemented in **Fixed rule** and **Weighted rule**.  \n",
    "ML is used as a controlled enhancement, but we still encode the same structure via interaction features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1157892",
   "metadata": {},
   "source": [
    "---\n",
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc725518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d264b8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Load raw data + shuffle rows\n",
    "\n",
    "We shuffle to avoid any ordering artifacts in later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb491a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data.csv\")  # <-- change to your real file path\n",
    "\n",
    "def make_synthetic_data(n=9000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return pd.DataFrame({\n",
    "        \"ID\": rng.integers(1, n//2 + 1, size=n),\n",
    "        \"IO_TYPE\": rng.choice([\"normal\", \"zombie\"], size=n, p=[0.97, 0.03]),\n",
    "        \"LIFE_CYCLE\": rng.choice([\"open\", \"closed\"], size=n, p=[0.9, 0.1]),\n",
    "        \"OFFERING_NAME\": rng.choice(\n",
    "            [\"Core\", \"Standard\", \"ESG Plus\", \"SI Focus\", \"Core SI\", \"Income\", \"SI Sustainable\", None],\n",
    "            size=n, p=[0.23,0.23,0.14,0.14,0.08,0.07,0.06,0.05]\n",
    "        ),\n",
    "        \"SI_CONSIDERATION_CD\": rng.choice([\"S1\",\"S2\",\"S3\", None], size=n, p=[0.35,0.35,0.2,0.1]),\n",
    "        \"SFDR_PREF\": rng.choice([\"F1\",\"F2\",\"F3\", None], size=n, p=[0.4,0.35,0.2,0.05]),\n",
    "        \"SFDR_ACTUAL\": rng.choice([\"F1\",\"F2\",\"F3\", None], size=n, p=[0.45,0.35,0.15,0.05]),\n",
    "        \"PAI_PREF\": rng.choice([\"PAI Selected\", None], size=n, p=[0.3,0.7]),\n",
    "        \"MIFID\": rng.choice([\"Yes\",\"No\", None], size=n, p=[0.55,0.4,0.05]),\n",
    "        \"TAXONOMYPREF\": rng.choice([\"A1\",\"A2\",\"A3\", None], size=n, p=[0.5,0.35,0.1,0.05]),\n",
    "        \"GHG\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.25,0.65,0.05,0.05]),\n",
    "        \"Biodiversity\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.2,0.7,0.05,0.05]),\n",
    "        \"Water\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.22,0.68,0.05,0.05]),\n",
    "        \"Waste\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.18,0.72,0.05,0.05]),\n",
    "        \"Social\": rng.choice([\"Yes\",\"No\",\"--\", None], size=n, p=[0.28,0.62,0.05,0.05]),\n",
    "    })\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    df_raw = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Loaded: {DATA_PATH}  shape={df_raw.shape}\")\n",
    "else:\n",
    "    df_raw = make_synthetic_data()\n",
    "    print(\"DATA_PATH not found; using synthetic demo dataset.\")\n",
    "    print(f\"shape={df_raw.shape}\")\n",
    "\n",
    "df_raw = df_raw.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7496ec",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Cleaning & filtering (ONLY)\n",
    "\n",
    "This step is **data hygiene only**.\n",
    "\n",
    "**We do:** filter out non-actionable rows and standardize missing placeholders.\n",
    "**We do NOT:** map categories to numbers here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab23aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_RAW = [\n",
    "    \"ID\",\"IO_TYPE\",\"LIFE_CYCLE\",\"OFFERING_NAME\",\n",
    "    \"SI_CONSIDERATION_CD\",\"SFDR_PREF\",\"SFDR_ACTUAL\",\"PAI_PREF\",\"MIFID\",\"TAXONOMYPREF\",\n",
    "    \"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"\n",
    "]\n",
    "missing_cols = [c for c in REQUIRED_RAW if c not in df_raw.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required raw columns: {missing_cols}\")\n",
    "\n",
    "def clean_filter_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # strip whitespace for object cols\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            df[c] = df[c].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    # standardize placeholder missing\n",
    "    df = df.replace({\"--\": np.nan, \"\": np.nan})\n",
    "\n",
    "    before = len(df)\n",
    "    df = df[df[\"IO_TYPE\"].fillna(\"\").str.lower() != \"zombie\"]\n",
    "    after_zombie = len(df)\n",
    "    df = df[df[\"LIFE_CYCLE\"].fillna(\"\").str.lower() == \"open\"]\n",
    "    after_open = len(df)\n",
    "\n",
    "    df.attrs[\"cleaning_summary\"] = {\n",
    "        \"before\": before,\n",
    "        \"after_remove_zombie\": after_zombie,\n",
    "        \"after_keep_open\": after_open,\n",
    "        \"removed_zombie\": before - after_zombie,\n",
    "        \"removed_closed\": after_zombie - after_open\n",
    "    }\n",
    "    return df\n",
    "\n",
    "df_clean_rows = clean_filter_only(df_raw)\n",
    "pd.DataFrame([df_clean_rows.attrs[\"cleaning_summary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charts: cleaning impact + missingness snapshot\n",
    "s = df_clean_rows.attrs[\"cleaning_summary\"]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar([\"Before\", \"After zombie\", \"After open\"], [s[\"before\"], s[\"after_remove_zombie\"], s[\"after_keep_open\"]])\n",
    "plt.title(\"Cleaning impact: rows remaining after filters\")\n",
    "plt.ylabel(\"Rows\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "key_cols = [\"SI_CONSIDERATION_CD\",\"SFDR_PREF\",\"SFDR_ACTUAL\",\"TAXONOMYPREF\",\"MIFID\",\"PAI_PREF\",\n",
    "            \"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\",\"OFFERING_NAME\"]\n",
    "miss = df_clean_rows[key_cols].isna().mean().sort_values(ascending=False)\n",
    "display(miss.to_frame(\"missing_rate\").head(12))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(miss.index[:12], miss.values[:12])\n",
    "plt.title(\"Top missing rates after cleaning (raw values, before encoding)\")\n",
    "plt.ylabel(\"Missing rate\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59992045",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) Derive proxy label and aggregate to ID-level\n",
    "\n",
    "We now derive `si_offering` and aggregate to one row per ID (unit of action)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e042ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean_rows.copy()\n",
    "\n",
    "# Row-level SI membership derived from OFFERING_NAME\n",
    "df[\"si_offering_row\"] = df[\"OFFERING_NAME\"].astype(str).str.contains(r\"\\bSI\\b\", case=False, na=False).astype(int)\n",
    "\n",
    "def mode_or_first(s: pd.Series):\n",
    "    s2 = s.dropna()\n",
    "    if len(s2) == 0:\n",
    "        return np.nan\n",
    "    m = s2.mode()\n",
    "    return m.iloc[0] if len(m) else s2.iloc[0]\n",
    "\n",
    "agg_dict = {\n",
    "    \"IO_TYPE\": mode_or_first,\n",
    "    \"LIFE_CYCLE\": mode_or_first,\n",
    "    \"OFFERING_NAME\": mode_or_first,  # transparency only (not used as feature)\n",
    "    \"SI_CONSIDERATION_CD\": mode_or_first,\n",
    "    \"SFDR_PREF\": mode_or_first,\n",
    "    \"SFDR_ACTUAL\": mode_or_first,\n",
    "    \"PAI_PREF\": mode_or_first,\n",
    "    \"MIFID\": mode_or_first,\n",
    "    \"TAXONOMYPREF\": mode_or_first,\n",
    "    \"GHG\": mode_or_first,\n",
    "    \"Biodiversity\": mode_or_first,\n",
    "    \"Water\": mode_or_first,\n",
    "    \"Waste\": mode_or_first,\n",
    "    \"Social\": mode_or_first,\n",
    "    \"si_offering_row\": \"max\",\n",
    "}\n",
    "\n",
    "df_id = df.groupby(\"ID\", as_index=False).agg(agg_dict).rename(columns={\"si_offering_row\":\"si_offering\"})\n",
    "\n",
    "sizes = pd.DataFrame({\n",
    "    \"level\": [\"row-level (cleaned)\", \"ID-level\"],\n",
    "    \"rows\": [len(df), len(df_id)],\n",
    "    \"si_offering_rate\": [df[\"si_offering_row\"].mean(), df_id[\"si_offering\"].mean()]\n",
    "})\n",
    "display(sizes)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(sizes[\"level\"], sizes[\"rows\"])\n",
    "plt.title(\"Size: cleaned rows vs ID-level\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(sizes[\"level\"], sizes[\"si_offering_rate\"])\n",
    "plt.title(\"Proxy label prevalence: si_offering rate\")\n",
    "plt.ylabel(\"Rate\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b7602",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Feature encoding & engineering (numbers happen here)\n",
    "\n",
    "This section converts business fields into numeric signals for scoring and ML.\n",
    "\n",
    "### Key engineered signals\n",
    "- `sfdr_gap = clip(pref - actual, -2, 2)`; `sfdr_opp = max(sfdr_gap, 0)`\n",
    "- `pai_block` = 0 if no PAI, else 0.5 + 0.5*topics_norm\n",
    "- `tax_norm` scales A1/A2/A3 → 0..1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SI = {\"S1\":1, \"S2\":2, \"S3\":3}\n",
    "MAP_SFDR = {\"F1\":1, \"F2\":2, \"F3\":3}\n",
    "MAP_TAX = {\"A1\":1, \"A2\":2, \"A3\":3}\n",
    "\n",
    "def yes_to_1(x):\n",
    "    return 1 if isinstance(x, str) and x.strip().lower() == \"yes\" else 0\n",
    "\n",
    "def encode_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Binary fields\n",
    "    for c in [\"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"]:\n",
    "        df[c] = df[c].apply(yes_to_1).astype(int)\n",
    "\n",
    "    df[\"MIFID\"] = df[\"MIFID\"].apply(yes_to_1).astype(int)\n",
    "    df[\"PAI_PREF\"] = (df[\"PAI_PREF\"].astype(str).str.lower() == \"pai selected\").astype(int)\n",
    "\n",
    "    # Ordinals (conservative default to lowest tier)\n",
    "    df[\"SI_CONSIDERATION_num\"] = df[\"SI_CONSIDERATION_CD\"].map(MAP_SI).fillna(1).astype(int)\n",
    "    df[\"SFDR_PREF_num\"] = df[\"SFDR_PREF\"].map(MAP_SFDR).fillna(1).astype(int)\n",
    "    df[\"SFDR_ACTUAL_num\"] = df[\"SFDR_ACTUAL\"].map(MAP_SFDR).fillna(1).astype(int)\n",
    "    df[\"TAXONOMYPREF_num\"] = df[\"TAXONOMYPREF\"].map(MAP_TAX).fillna(1).astype(int)\n",
    "\n",
    "    # SFDR engineered\n",
    "    df[\"sfdr_gap\"] = np.clip(df[\"SFDR_PREF_num\"] - df[\"SFDR_ACTUAL_num\"], -2, 2)\n",
    "    df[\"sfdr_opp\"] = np.maximum(df[\"sfdr_gap\"], 0)  # 0..2\n",
    "\n",
    "    # Topics aggregate\n",
    "    topic_cols = [\"GHG\",\"Biodiversity\",\"Water\",\"Waste\",\"Social\"]\n",
    "    df[\"esg_topics_yes_cnt\"] = df[topic_cols].sum(axis=1)\n",
    "    df[\"topics_norm\"] = df[\"esg_topics_yes_cnt\"] / len(topic_cols)\n",
    "\n",
    "    # Normalized signals (0..1)\n",
    "    df[\"si_norm\"] = np.clip((df[\"SI_CONSIDERATION_num\"] - 1)/2, 0, 1)\n",
    "    df[\"sfdr_norm\"] = np.clip(df[\"sfdr_opp\"]/2, 0, 1)\n",
    "    df[\"tax_norm\"] = np.clip((df[\"TAXONOMYPREF_num\"] - 1)/2, 0, 1)\n",
    "\n",
    "    # PAI block (0..1)\n",
    "    df[\"pai_block\"] = np.where(df[\"PAI_PREF\"]==1, 0.5 + 0.5*df[\"topics_norm\"], 0.0)\n",
    "\n",
    "    # Business logic helper\n",
    "    df[\"si_is_s3\"] = (df[\"SI_CONSIDERATION_num\"] == 3).astype(int)\n",
    "\n",
    "    df[\"si_offering\"] = df[\"si_offering\"].astype(int)\n",
    "    return df\n",
    "\n",
    "df_feat = encode_features(df_id)\n",
    "\n",
    "# Sanity-check distributions\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_feat[\"sfdr_gap\"], bins=5)\n",
    "plt.title(\"Distribution: sfdr_gap (clipped)\")\n",
    "plt.xlabel(\"sfdr_gap\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_feat[\"TAXONOMYPREF_num\"], bins=3)\n",
    "plt.title(\"Distribution: TAXONOMYPREF_num (A1/A2/A3 -> 1/2/3)\")\n",
    "plt.xlabel(\"TAXONOMYPREF_num\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_feat[[\"ID\",\"si_offering\",\"MIFID\",\"SI_CONSIDERATION_num\",\"si_is_s3\",\"sfdr_gap\",\"PAI_PREF\",\"TAXONOMYPREF_num\",\"esg_topics_yes_cnt\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b00f99",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) Train/Validation split (ID-level)\n",
    "\n",
    "All three methods are evaluated on the **same** validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58719d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_BASE = [\"MIFID\",\"SI_CONSIDERATION_num\",\"si_is_s3\",\"sfdr_norm\",\"pai_block\",\"tax_norm\"]\n",
    "\n",
    "X = df_feat[FEATURES_BASE].copy()\n",
    "y = df_feat[\"si_offering\"].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "idx_train, idx_val = X_train.index, X_val.index\n",
    "\n",
    "print(\"Train:\", len(idx_train), \"Val:\", len(idx_val))\n",
    "print(\"Train si_offering rate:\", y_train.mean().round(4))\n",
    "print(\"Val   si_offering rate:\", y_val.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009ad3f",
   "metadata": {},
   "source": [
    "---\n",
    "## 6) Evaluation helpers (metrics + lift + calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_scores(y_true, p, label):\n",
    "    return {\n",
    "        \"model\": label,\n",
    "        \"auc\": roc_auc_score(y_true, p),\n",
    "        \"avg_precision\": average_precision_score(y_true, p),\n",
    "        \"brier\": brier_score_loss(y_true, p)\n",
    "    }\n",
    "\n",
    "def lift_table(y_true, p, n_bins=10):\n",
    "    tmp = pd.DataFrame({\"y\": y_true, \"p\": p})\n",
    "    tmp[\"bin\"] = pd.qcut(tmp[\"p\"], n_bins, labels=False, duplicates=\"drop\") + 1\n",
    "    return tmp.groupby(\"bin\")[\"y\"].agg([\"mean\",\"count\"]).rename(columns={\"mean\":\"si_rate\"})\n",
    "\n",
    "def plot_lift(tab, title):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(tab.index, tab[\"si_rate\"].values, marker=\"o\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Decile (1=lowest score, 10=highest)\")\n",
    "    plt.ylabel(\"si_offering rate\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_calibration(y_true, p, title):\n",
    "    prob_true, prob_pred = calibration_curve(y_true, p, n_bins=10, strategy=\"quantile\")\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(prob_pred, prob_true, marker=\"o\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Observed si_offering rate\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ccbd6",
   "metadata": {},
   "source": [
    "---\n",
    "## 7) Method 1 — Fixed rule (stakeholder weights)\n",
    "\n",
    "### Logic implemented\n",
    "- If `MIFID=0`: **only** SI_CONSIDERATION\n",
    "- If `MIFID=1` and `SI=S3`: add confirmation from SFDR/PAI/Taxonomy\n",
    "- If `MIFID=1` and `SI!=S3`: keep a conservative baseline\n",
    "\n",
    "We also compute **“why columns”** (contributions) so each recommendation is explainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FixedRuleConfig:\n",
    "    # MIFID=0 branch: only SI\n",
    "    score_A_S1: float = 0\n",
    "    score_A_S2: float = 45\n",
    "    score_A_S3: float = 85\n",
    "\n",
    "    # MIFID=1 branch:\n",
    "    baseline_B_S1: float = 0\n",
    "    baseline_B_S2: float = 30\n",
    "    baseline_B_S3: float = 50\n",
    "\n",
    "    confirm_max: float = 50  # max added if SI is high (S3)\n",
    "    w_sfdr: float = 0.50\n",
    "    w_pai: float = 0.30\n",
    "    w_tax: float = 0.20\n",
    "\n",
    "cfg_fixed = FixedRuleConfig()\n",
    "\n",
    "def score_fixed_rule(df: pd.DataFrame, cfg: FixedRuleConfig) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Baselines\n",
    "    base_A = df[\"SI_CONSIDERATION_num\"].map({1: cfg.score_A_S1, 2: cfg.score_A_S2, 3: cfg.score_A_S3}).astype(float)\n",
    "    base_B = df[\"SI_CONSIDERATION_num\"].map({1: cfg.baseline_B_S1, 2: cfg.baseline_B_S2, 3: cfg.baseline_B_S3}).astype(float)\n",
    "\n",
    "    confirm = cfg.confirm_max * (\n",
    "        cfg.w_sfdr * df[\"sfdr_norm\"] +\n",
    "        cfg.w_pai * df[\"pai_block\"] +\n",
    "        cfg.w_tax * df[\"tax_norm\"]\n",
    "    )\n",
    "\n",
    "    # Apply requested gate: only add confirm when MIFID=1 and SI=S3\n",
    "    score = np.where(df[\"MIFID\"]==0, base_A,\n",
    "                     np.where(df[\"si_is_s3\"]==1, base_B + confirm, base_B))\n",
    "\n",
    "    df[\"score_fixed\"] = np.clip(score, 0, 100)\n",
    "\n",
    "    # Why columns\n",
    "    df[\"why_base\"] = np.where(df[\"MIFID\"]==0, base_A, base_B)\n",
    "    df[\"why_sfdr\"] = np.where((df[\"MIFID\"]==1) & (df[\"si_is_s3\"]==1), cfg.confirm_max*cfg.w_sfdr*df[\"sfdr_norm\"], 0.0)\n",
    "    df[\"why_pai\"]  = np.where((df[\"MIFID\"]==1) & (df[\"si_is_s3\"]==1), cfg.confirm_max*cfg.w_pai*df[\"pai_block\"], 0.0)\n",
    "    df[\"why_tax\"]  = np.where((df[\"MIFID\"]==1) & (df[\"si_is_s3\"]==1), cfg.confirm_max*cfg.w_tax*df[\"tax_norm\"], 0.0)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_scored = score_fixed_rule(df_feat, cfg_fixed)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_scored[\"score_fixed\"], bins=30)\n",
    "plt.title(\"Score distribution: Fixed rule\")\n",
    "plt.xlabel(\"score_fixed\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_scored[[\"score_fixed\",\"why_base\",\"why_sfdr\",\"why_pai\",\"why_tax\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b87d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation performance (Fixed rule)\n",
    "p_fixed = df_scored.loc[idx_val, \"score_fixed\"].values / 100.0\n",
    "fixed_metrics = eval_scores(y_val.values, p_fixed, \"Fixed rule\")\n",
    "display(fixed_metrics)\n",
    "\n",
    "lift_fixed = lift_table(y_val.values, p_fixed)\n",
    "plot_lift(lift_fixed, \"Lift (proxy): Fixed rule\")\n",
    "display(lift_fixed)\n",
    "\n",
    "plot_calibration(y_val.values, p_fixed, \"Calibration (proxy): Fixed rule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310e765",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Method 2 — Weighted rule (data-driven, still rule-like)\n",
    "\n",
    "We keep the **same structure**, but learn the **confirmation weights** from data.\n",
    "\n",
    "Training subset for learning weights:\n",
    "- `MIFID=1` and `SI=S3` (only population where confirmation signals apply)\n",
    "\n",
    "We fit logistic regression on train and convert positive coefficients into weights that sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffbbdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_scored.loc[idx_train].copy()\n",
    "train_gate = train_df[(train_df[\"MIFID\"]==1) & (train_df[\"si_is_s3\"]==1)].copy()\n",
    "\n",
    "WEIGHT_FEATURES = [\"sfdr_norm\",\"pai_block\",\"tax_norm\"]\n",
    "if train_gate[\"si_offering\"].nunique() < 2:\n",
    "    print(\"Warning: gated training subset has only one class; falling back to fixed weights.\")\n",
    "    w_learned = pd.Series([cfg_fixed.w_sfdr, cfg_fixed.w_pai, cfg_fixed.w_tax], index=WEIGHT_FEATURES)\n",
    "else:\n",
    "    lr_w = LogisticRegression(max_iter=6000, class_weight=\"balanced\")\n",
    "    lr_w.fit(train_gate[WEIGHT_FEATURES], train_gate[\"si_offering\"])\n",
    "    coef = pd.Series(lr_w.coef_[0], index=WEIGHT_FEATURES)\n",
    "\n",
    "    pos = np.maximum(coef.values, 0)  # stakeholder-friendly monotonic assumption\n",
    "    if pos.sum() == 0:\n",
    "        pos = np.ones_like(pos)\n",
    "    w_learned = pd.Series(pos / pos.sum(), index=WEIGHT_FEATURES)\n",
    "\n",
    "display(w_learned.to_frame(\"learned_weight\"))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(w_learned.index, w_learned.values)\n",
    "plt.title(\"Weighted rule: learned confirmation weights (sum=1)\")\n",
    "plt.ylabel(\"weight\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d29102",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WeightedRuleConfig:\n",
    "    score_A_S1: float = cfg_fixed.score_A_S1\n",
    "    score_A_S2: float = cfg_fixed.score_A_S2\n",
    "    score_A_S3: float = cfg_fixed.score_A_S3\n",
    "\n",
    "    baseline_B_S1: float = cfg_fixed.baseline_B_S1\n",
    "    baseline_B_S2: float = cfg_fixed.baseline_B_S2\n",
    "    baseline_B_S3: float = cfg_fixed.baseline_B_S3\n",
    "\n",
    "    confirm_max: float = cfg_fixed.confirm_max\n",
    "\n",
    "cfg_weighted = WeightedRuleConfig()\n",
    "\n",
    "def score_weighted_rule(df: pd.DataFrame, cfg: WeightedRuleConfig, w: pd.Series) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    base_A = df[\"SI_CONSIDERATION_num\"].map({1: cfg.score_A_S1, 2: cfg.score_A_S2, 3: cfg.score_A_S3}).astype(float)\n",
    "    base_B = df[\"SI_CONSIDERATION_num\"].map({1: cfg.baseline_B_S1, 2: cfg.baseline_B_S2, 3: cfg.baseline_B_S3}).astype(float)\n",
    "\n",
    "    confirm = cfg.confirm_max * (\n",
    "        w[\"sfdr_norm\"] * df[\"sfdr_norm\"] +\n",
    "        w[\"pai_block\"] * df[\"pai_block\"] +\n",
    "        w[\"tax_norm\"] * df[\"tax_norm\"]\n",
    "    )\n",
    "\n",
    "    score = np.where(df[\"MIFID\"]==0, base_A,\n",
    "                     np.where(df[\"si_is_s3\"]==1, base_B + confirm, base_B))\n",
    "\n",
    "    df[\"score_weighted\"] = np.clip(score, 0, 100)\n",
    "\n",
    "    df[\"whyW_base\"] = np.where(df[\"MIFID\"]==0, base_A, base_B)\n",
    "    df[\"whyW_sfdr\"] = np.where((df[\"MIFID\"]==1) & (df[\"si_is_s3\"]==1), cfg.confirm_max*w[\"sfdr_norm\"]*df[\"sfdr_norm\"], 0.0)\n",
    "    df[\"whyW_pai\"]  = np.where((df[\"MIFID\"]==1) & (df[\"si_is_s3\"]==1), cfg.confirm_max*w[\"pai_block\"]*df[\"pai_block\"], 0.0)\n",
    "    df[\"whyW_tax\"]  = np.where((df[\"MIFID\"]==1) & (df[\"si_is_s3\"]==1), cfg.confirm_max*w[\"tax_norm\"]*df[\"tax_norm\"], 0.0)\n",
    "    return df\n",
    "\n",
    "df_scored = score_weighted_rule(df_scored, cfg_weighted, w_learned)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df_scored[\"score_weighted\"], bins=30)\n",
    "plt.title(\"Score distribution: Weighted rule (data-driven)\")\n",
    "plt.xlabel(\"score_weighted\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_scored[[\"score_weighted\",\"whyW_base\",\"whyW_sfdr\",\"whyW_pai\",\"whyW_tax\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation performance (Weighted rule)\n",
    "p_weighted = df_scored.loc[idx_val, \"score_weighted\"].values / 100.0\n",
    "weighted_metrics = eval_scores(y_val.values, p_weighted, \"Weighted rule (data-driven)\")\n",
    "display(weighted_metrics)\n",
    "\n",
    "lift_weighted = lift_table(y_val.values, p_weighted)\n",
    "plot_lift(lift_weighted, \"Lift (proxy): Weighted rule\")\n",
    "display(lift_weighted)\n",
    "\n",
    "plot_calibration(y_val.values, p_weighted, \"Calibration (proxy): Weighted rule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c7a5b",
   "metadata": {},
   "source": [
    "---\n",
    "## 9) Method 3 — ML: Calibrated Logistic Regression (controlled enhancement)\n",
    "\n",
    "We fit a calibrated LR to produce **probabilities**.\n",
    "\n",
    "To respect the business structure, we include **interaction features** that approximate the gate:\n",
    "- `gate = MIFID * si_is_s3`\n",
    "- `gate * sfdr_norm`, `gate * pai_block`, `gate * tax_norm`\n",
    "\n",
    "This allows ML to learn within the same conceptual framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ml_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = df[FEATURES_BASE].copy()\n",
    "    X[\"gate\"] = X[\"MIFID\"] * X[\"si_is_s3\"]\n",
    "    X[\"gate_sfdr\"] = X[\"gate\"] * X[\"sfdr_norm\"]\n",
    "    X[\"gate_pai\"]  = X[\"gate\"] * X[\"pai_block\"]\n",
    "    X[\"gate_tax\"]  = X[\"gate\"] * X[\"tax_norm\"]\n",
    "    return X\n",
    "\n",
    "Xtr = make_ml_matrix(df_scored.loc[idx_train])\n",
    "Xva = make_ml_matrix(df_scored.loc[idx_val])\n",
    "\n",
    "lr = LogisticRegression(max_iter=8000, class_weight=\"balanced\")\n",
    "cal_lr = CalibratedClassifierCV(lr, method=\"isotonic\", cv=5)\n",
    "cal_lr.fit(Xtr, y_train)\n",
    "\n",
    "p_ml = cal_lr.predict_proba(Xva)[:,1]\n",
    "ml_metrics = eval_scores(y_val.values, p_ml, \"ML: Calibrated Logistic Regression\")\n",
    "display(ml_metrics)\n",
    "\n",
    "lift_ml = lift_table(y_val.values, p_ml)\n",
    "plot_lift(lift_ml, \"Lift (proxy): ML Calibrated Logistic Regression\")\n",
    "display(lift_ml)\n",
    "\n",
    "plot_calibration(y_val.values, p_ml, \"Calibration (proxy): ML Calibrated Logistic Regression\")\n",
    "\n",
    "# Interpretability: coefficients from uncalibrated LR on same features\n",
    "lr_plain = LogisticRegression(max_iter=8000, class_weight=\"balanced\")\n",
    "lr_plain.fit(Xtr, y_train)\n",
    "coef = pd.Series(lr_plain.coef_[0], index=Xtr.columns).sort_values(key=np.abs, ascending=False)\n",
    "display(coef.to_frame(\"coef\"))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(coef.index[:12], coef.values[:12])\n",
    "plt.title(\"Top coefficients (uncalibrated LR; sign indicates direction)\")\n",
    "plt.ylabel(\"coef\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f8fa5",
   "metadata": {},
   "source": [
    "---\n",
    "## 10) Validation comparison (Fixed vs Weighted vs ML)\n",
    "\n",
    "This is the stakeholder-ready head-to-head comparison on the **same** validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame([fixed_metrics, weighted_metrics, ml_metrics]).round(4)\n",
    "display(comparison.sort_values(\"auc\", ascending=False))\n",
    "\n",
    "for metric in [\"auc\",\"avg_precision\",\"brier\"]:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(comparison[\"model\"], comparison[metric])\n",
    "    plt.title(f\"Validation comparison: {metric}\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b2a94",
   "metadata": {},
   "source": [
    "---\n",
    "## 11) Operational output: Top 20 IDs with `si_offering=0` + “why” columns\n",
    "\n",
    "Operationally, use a score available for all IDs (Fixed or Weighted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d1c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK_METHOD = \"score_weighted\"  # \"score_fixed\" or \"score_weighted\"\n",
    "\n",
    "df_out = df_scored.copy()\n",
    "df_out[\"rank_score\"] = df_out[RANK_METHOD]\n",
    "df_out[\"score_percentile\"] = (df_out[\"rank_score\"].rank(pct=True) * 100).round(2)\n",
    "df_out[\"bucket_3\"] = pd.cut(df_out[\"score_percentile\"], bins=[-0.01, 50, 80, 100], labels=[\"Low\",\"Average\",\"High\"])\n",
    "\n",
    "targets = df_out[df_out[\"si_offering\"]==0].sort_values(\"rank_score\", ascending=False)\n",
    "\n",
    "if RANK_METHOD == \"score_fixed\":\n",
    "    why_cols = [\"why_base\",\"why_sfdr\",\"why_pai\",\"why_tax\"]\n",
    "else:\n",
    "    why_cols = [\"whyW_base\",\"whyW_sfdr\",\"whyW_pai\",\"whyW_tax\"]\n",
    "\n",
    "cols = [\"ID\",\"rank_score\",\"score_percentile\",\"bucket_3\",\n",
    "        \"MIFID\",\"SI_CONSIDERATION_num\",\"sfdr_gap\",\"PAI_PREF\",\"TAXONOMYPREF_num\",\"esg_topics_yes_cnt\"] + why_cols\n",
    "\n",
    "targets[cols].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ce856",
   "metadata": {},
   "source": [
    "---\n",
    "## 12) Risks & governance (what stakeholders should know)\n",
    "\n",
    "- **Proxy label bias**: `si_offering` is membership, not true interest.\n",
    "- **Hard gate risk** (requested logic): if SFDR/PAI/Tax only apply when SI=S3, we may miss some opportunities.\n",
    "- **Missing data**: defaults to lowest tier can under-score; monitor missingness.\n",
    "\n",
    "Mitigations:\n",
    "- Treat scores as prioritization; validate via pilot.\n",
    "- Monitor lift and calibration over time.\n",
    "- Refit weights quarterly (or after product/process changes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085910f",
   "metadata": {},
   "source": [
    "---\n",
    "## 13) Pilot plan (to get real labels)\n",
    "\n",
    "Use this model to run a controlled pilot and collect **true outcomes**:\n",
    "- Treatment: High bucket among `si_offering=0`\n",
    "- Control: randomized sample from eligible pool\n",
    "- Outcomes: response, meeting booked, adoption, pipeline created\n",
    "\n",
    "Then retrain ML on true outcomes and re-compare Fixed vs Weighted vs ML."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
